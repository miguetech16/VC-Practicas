{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  \n",
    "import math \n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "from ultralytics import YOLO\n",
    "import easyocr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelos preentrenados, visualizando con las utilidades de ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "WARNING  inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (frame 1/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 163.5ms\n",
      "video 1/1 (frame 2/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 126.5ms\n",
      "video 1/1 (frame 3/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 127.5ms\n",
      "video 1/1 (frame 4/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 142.5ms\n",
      "video 1/1 (frame 5/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 139.6ms\n",
      "video 1/1 (frame 6/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 136.1ms\n",
      "video 1/1 (frame 7/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 120.0ms\n",
      "video 1/1 (frame 8/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 111.7ms\n",
      "video 1/1 (frame 9/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 113.5ms\n",
      "video 1/1 (frame 10/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 134.7ms\n",
      "video 1/1 (frame 11/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 153.0ms\n",
      "video 1/1 (frame 12/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 144.5ms\n",
      "video 1/1 (frame 13/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 162.0ms\n",
      "video 1/1 (frame 14/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 121.0ms\n",
      "video 1/1 (frame 15/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 120.7ms\n",
      "video 1/1 (frame 16/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 123.0ms\n",
      "video 1/1 (frame 17/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 135.7ms\n",
      "video 1/1 (frame 18/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 124.0ms\n",
      "video 1/1 (frame 19/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 136.0ms\n",
      "video 1/1 (frame 20/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 123.0ms\n",
      "video 1/1 (frame 21/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 118.9ms\n",
      "video 1/1 (frame 22/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 112.2ms\n",
      "video 1/1 (frame 23/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 131.0ms\n",
      "video 1/1 (frame 24/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 185.1ms\n",
      "video 1/1 (frame 25/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 221.6ms\n",
      "video 1/1 (frame 26/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 213.6ms\n",
      "video 1/1 (frame 27/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 185.7ms\n",
      "video 1/1 (frame 28/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 136.8ms\n",
      "video 1/1 (frame 29/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 241.5ms\n",
      "video 1/1 (frame 30/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 188.1ms\n",
      "video 1/1 (frame 31/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 124.0ms\n",
      "video 1/1 (frame 32/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 115.0ms\n",
      "video 1/1 (frame 33/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 128.7ms\n",
      "video 1/1 (frame 34/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 116.0ms\n",
      "video 1/1 (frame 35/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 122.2ms\n",
      "video 1/1 (frame 36/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 151.1ms\n",
      "video 1/1 (frame 37/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 123.5ms\n",
      "video 1/1 (frame 38/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 125.3ms\n",
      "video 1/1 (frame 39/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 122.3ms\n",
      "video 1/1 (frame 40/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 183.7ms\n",
      "video 1/1 (frame 41/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 129.7ms\n",
      "video 1/1 (frame 42/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 263.1ms\n",
      "video 1/1 (frame 43/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 140.1ms\n",
      "video 1/1 (frame 44/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 123.6ms\n",
      "video 1/1 (frame 45/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 111.6ms\n",
      "video 1/1 (frame 46/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 109.0ms\n",
      "video 1/1 (frame 47/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 107.8ms\n",
      "video 1/1 (frame 48/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 122.3ms\n",
      "video 1/1 (frame 49/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 132.0ms\n",
      "video 1/1 (frame 50/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 138.6ms\n",
      "video 1/1 (frame 51/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 121.9ms\n",
      "video 1/1 (frame 52/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 117.5ms\n",
      "video 1/1 (frame 53/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 121.0ms\n",
      "video 1/1 (frame 54/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 124.0ms\n",
      "video 1/1 (frame 55/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 146.1ms\n",
      "video 1/1 (frame 56/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 135.0ms\n",
      "video 1/1 (frame 57/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 128.0ms\n",
      "video 1/1 (frame 58/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 126.0ms\n",
      "video 1/1 (frame 59/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 114.3ms\n",
      "video 1/1 (frame 60/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 121.6ms\n",
      "video 1/1 (frame 61/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 109.5ms\n",
      "video 1/1 (frame 62/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 117.8ms\n",
      "video 1/1 (frame 63/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 127.6ms\n",
      "video 1/1 (frame 64/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 128.6ms\n",
      "video 1/1 (frame 65/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 120.1ms\n",
      "video 1/1 (frame 66/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 118.0ms\n",
      "video 1/1 (frame 67/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 113.0ms\n",
      "video 1/1 (frame 68/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 108.8ms\n",
      "video 1/1 (frame 69/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 111.1ms\n",
      "video 1/1 (frame 70/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 115.7ms\n",
      "video 1/1 (frame 71/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 108.1ms\n",
      "video 1/1 (frame 72/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 117.1ms\n",
      "video 1/1 (frame 73/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 117.9ms\n",
      "video 1/1 (frame 74/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 111.5ms\n",
      "video 1/1 (frame 75/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 110.7ms\n",
      "video 1/1 (frame 76/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 112.5ms\n",
      "video 1/1 (frame 77/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 106.4ms\n",
      "video 1/1 (frame 78/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 112.1ms\n",
      "video 1/1 (frame 79/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 117.1ms\n",
      "video 1/1 (frame 80/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 116.0ms\n",
      "video 1/1 (frame 81/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 124.0ms\n",
      "video 1/1 (frame 82/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 120.1ms\n",
      "video 1/1 (frame 83/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 146.6ms\n",
      "video 1/1 (frame 84/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 156.7ms\n",
      "video 1/1 (frame 85/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 120.1ms\n",
      "video 1/1 (frame 86/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 110.1ms\n",
      "video 1/1 (frame 87/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 104.7ms\n",
      "video 1/1 (frame 88/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 112.0ms\n",
      "video 1/1 (frame 89/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 104.1ms\n",
      "video 1/1 (frame 90/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 119.0ms\n",
      "video 1/1 (frame 91/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 114.0ms\n",
      "video 1/1 (frame 92/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 105.6ms\n",
      "video 1/1 (frame 93/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 107.0ms\n",
      "video 1/1 (frame 94/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 110.0ms\n",
      "video 1/1 (frame 95/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 108.0ms\n",
      "video 1/1 (frame 96/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 134.0ms\n",
      "video 1/1 (frame 97/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 138.7ms\n",
      "video 1/1 (frame 98/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 118.1ms\n",
      "video 1/1 (frame 99/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 132.6ms\n",
      "video 1/1 (frame 100/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 174.6ms\n",
      "video 1/1 (frame 101/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 125.6ms\n",
      "video 1/1 (frame 102/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 153.0ms\n",
      "video 1/1 (frame 103/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 119.5ms\n",
      "video 1/1 (frame 104/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 123.5ms\n",
      "video 1/1 (frame 105/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 114.6ms\n",
      "video 1/1 (frame 106/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 111.0ms\n",
      "video 1/1 (frame 107/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 118.1ms\n",
      "video 1/1 (frame 108/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 140.5ms\n",
      "video 1/1 (frame 109/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 134.5ms\n",
      "video 1/1 (frame 110/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 127.0ms\n",
      "video 1/1 (frame 111/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 135.6ms\n",
      "video 1/1 (frame 112/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 132.5ms\n",
      "video 1/1 (frame 113/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 138.1ms\n",
      "video 1/1 (frame 114/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 159.1ms\n",
      "video 1/1 (frame 115/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 123.0ms\n",
      "video 1/1 (frame 116/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 164.7ms\n",
      "video 1/1 (frame 117/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 190.9ms\n",
      "video 1/1 (frame 118/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 190.8ms\n",
      "video 1/1 (frame 119/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 283.6ms\n",
      "video 1/1 (frame 120/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 186.6ms\n",
      "video 1/1 (frame 121/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 209.0ms\n",
      "video 1/1 (frame 122/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 579.3ms\n",
      "video 1/1 (frame 123/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 213.0ms\n",
      "video 1/1 (frame 124/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 177.5ms\n",
      "video 1/1 (frame 125/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 180.6ms\n",
      "video 1/1 (frame 126/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 150.1ms\n",
      "video 1/1 (frame 127/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 316.2ms\n",
      "video 1/1 (frame 128/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 211.0ms\n",
      "video 1/1 (frame 129/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 225.7ms\n",
      "video 1/1 (frame 130/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 220.1ms\n",
      "video 1/1 (frame 131/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 175.5ms\n",
      "video 1/1 (frame 132/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 144.6ms\n",
      "video 1/1 (frame 133/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 237.1ms\n",
      "video 1/1 (frame 134/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 175.2ms\n",
      "video 1/1 (frame 135/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 181.0ms\n",
      "video 1/1 (frame 136/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 138.0ms\n",
      "video 1/1 (frame 137/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 213.0ms\n",
      "video 1/1 (frame 138/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 158.1ms\n",
      "video 1/1 (frame 139/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 141.0ms\n",
      "video 1/1 (frame 140/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 207.8ms\n",
      "video 1/1 (frame 141/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 211.0ms\n",
      "video 1/1 (frame 142/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 205.1ms\n",
      "video 1/1 (frame 143/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 138.9ms\n",
      "video 1/1 (frame 144/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 165.9ms\n",
      "video 1/1 (frame 145/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 175.0ms\n",
      "video 1/1 (frame 146/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 160.0ms\n",
      "video 1/1 (frame 147/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 190.0ms\n",
      "video 1/1 (frame 148/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 233.6ms\n",
      "video 1/1 (frame 149/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 150.1ms\n",
      "video 1/1 (frame 150/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 185.1ms\n",
      "video 1/1 (frame 151/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 168.6ms\n",
      "video 1/1 (frame 152/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 149.1ms\n",
      "video 1/1 (frame 153/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 641.3ms\n",
      "video 1/1 (frame 154/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 206.3ms\n",
      "video 1/1 (frame 155/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 222.1ms\n",
      "video 1/1 (frame 156/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 374.1ms\n",
      "video 1/1 (frame 157/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 288.8ms\n",
      "video 1/1 (frame 158/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 168.0ms\n",
      "video 1/1 (frame 159/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 171.0ms\n",
      "video 1/1 (frame 160/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 181.6ms\n",
      "video 1/1 (frame 161/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 165.8ms\n",
      "video 1/1 (frame 162/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 201.1ms\n",
      "video 1/1 (frame 163/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 172.2ms\n",
      "video 1/1 (frame 164/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 159.9ms\n",
      "video 1/1 (frame 165/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 199.6ms\n",
      "video 1/1 (frame 166/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 205.0ms\n",
      "video 1/1 (frame 167/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 144.8ms\n",
      "video 1/1 (frame 168/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 167.2ms\n",
      "video 1/1 (frame 169/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 203.0ms\n",
      "video 1/1 (frame 170/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 198.1ms\n",
      "video 1/1 (frame 171/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 195.1ms\n",
      "video 1/1 (frame 172/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 155.0ms\n",
      "video 1/1 (frame 173/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 176.0ms\n",
      "video 1/1 (frame 174/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 165.0ms\n",
      "video 1/1 (frame 175/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 196.7ms\n",
      "video 1/1 (frame 176/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 165.0ms\n",
      "video 1/1 (frame 177/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 172.1ms\n",
      "video 1/1 (frame 178/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 154.5ms\n",
      "video 1/1 (frame 179/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 155.1ms\n",
      "video 1/1 (frame 180/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 221.1ms\n",
      "video 1/1 (frame 181/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 181.1ms\n",
      "video 1/1 (frame 182/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 156.1ms\n",
      "video 1/1 (frame 183/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 174.2ms\n",
      "video 1/1 (frame 184/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 198.0ms\n",
      "video 1/1 (frame 185/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 164.0ms\n",
      "video 1/1 (frame 186/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 162.1ms\n",
      "video 1/1 (frame 187/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 153.0ms\n",
      "video 1/1 (frame 188/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 207.3ms\n",
      "video 1/1 (frame 189/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 184.0ms\n",
      "video 1/1 (frame 190/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 216.6ms\n",
      "video 1/1 (frame 191/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 233.1ms\n",
      "video 1/1 (frame 192/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 250.6ms\n",
      "video 1/1 (frame 193/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 182.4ms\n",
      "video 1/1 (frame 194/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 181.0ms\n",
      "video 1/1 (frame 195/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 154.0ms\n",
      "video 1/1 (frame 196/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 201.6ms\n",
      "video 1/1 (frame 197/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 179.0ms\n",
      "video 1/1 (frame 198/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 230.2ms\n",
      "video 1/1 (frame 199/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 234.6ms\n",
      "video 1/1 (frame 200/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 197.1ms\n",
      "video 1/1 (frame 201/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 321.1ms\n",
      "video 1/1 (frame 202/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 254.6ms\n",
      "video 1/1 (frame 203/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 211.1ms\n",
      "video 1/1 (frame 204/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 185.1ms\n",
      "video 1/1 (frame 205/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 341.9ms\n",
      "video 1/1 (frame 206/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 334.6ms\n",
      "video 1/1 (frame 207/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 245.1ms\n",
      "video 1/1 (frame 208/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 213.3ms\n",
      "video 1/1 (frame 209/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 195.0ms\n",
      "video 1/1 (frame 210/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 270.1ms\n",
      "video 1/1 (frame 211/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 160.2ms\n",
      "video 1/1 (frame 212/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 206.2ms\n",
      "video 1/1 (frame 213/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 190.2ms\n",
      "video 1/1 (frame 214/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 189.7ms\n",
      "video 1/1 (frame 215/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 404.1ms\n",
      "video 1/1 (frame 216/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 255.6ms\n",
      "video 1/1 (frame 217/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 198.0ms\n",
      "video 1/1 (frame 218/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 172.1ms\n",
      "video 1/1 (frame 219/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 151.0ms\n",
      "video 1/1 (frame 220/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 197.1ms\n",
      "video 1/1 (frame 221/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 174.6ms\n",
      "video 1/1 (frame 222/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 171.6ms\n",
      "video 1/1 (frame 223/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 174.1ms\n",
      "video 1/1 (frame 224/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 155.1ms\n",
      "video 1/1 (frame 225/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 151.6ms\n",
      "video 1/1 (frame 226/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 225.6ms\n",
      "video 1/1 (frame 227/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 262.1ms\n",
      "video 1/1 (frame 228/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 171.1ms\n",
      "video 1/1 (frame 229/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 344.1ms\n",
      "video 1/1 (frame 230/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 186.6ms\n",
      "video 1/1 (frame 231/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 176.1ms\n",
      "video 1/1 (frame 232/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 129.9ms\n",
      "video 1/1 (frame 233/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 125.6ms\n",
      "video 1/1 (frame 234/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 132.0ms\n",
      "video 1/1 (frame 235/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 122.0ms\n",
      "video 1/1 (frame 236/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 124.0ms\n",
      "video 1/1 (frame 237/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 112.6ms\n",
      "video 1/1 (frame 238/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 126.1ms\n",
      "video 1/1 (frame 239/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 111.5ms\n",
      "video 1/1 (frame 240/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 115.6ms\n",
      "video 1/1 (frame 241/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 115.0ms\n",
      "video 1/1 (frame 242/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 121.5ms\n",
      "video 1/1 (frame 243/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 136.0ms\n",
      "video 1/1 (frame 244/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 115.6ms\n",
      "video 1/1 (frame 245/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 114.5ms\n",
      "video 1/1 (frame 246/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 108.1ms\n",
      "video 1/1 (frame 247/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 243.6ms\n",
      "video 1/1 (frame 248/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 132.0ms\n",
      "video 1/1 (frame 249/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 132.3ms\n",
      "video 1/1 (frame 250/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 116.6ms\n",
      "video 1/1 (frame 251/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 171.0ms\n",
      "video 1/1 (frame 252/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 129.1ms\n",
      "video 1/1 (frame 253/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 145.0ms\n",
      "video 1/1 (frame 254/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 115.5ms\n",
      "video 1/1 (frame 255/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 118.0ms\n",
      "video 1/1 (frame 256/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 115.0ms\n",
      "video 1/1 (frame 257/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 119.8ms\n",
      "video 1/1 (frame 258/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 132.1ms\n",
      "video 1/1 (frame 259/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 124.7ms\n",
      "video 1/1 (frame 260/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 106.0ms\n",
      "video 1/1 (frame 261/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 116.1ms\n",
      "video 1/1 (frame 262/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 120.5ms\n",
      "video 1/1 (frame 263/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 111.0ms\n",
      "video 1/1 (frame 264/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 113.0ms\n",
      "video 1/1 (frame 265/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 116.0ms\n",
      "video 1/1 (frame 266/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 116.8ms\n",
      "video 1/1 (frame 267/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 113.6ms\n",
      "video 1/1 (frame 268/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 125.5ms\n",
      "video 1/1 (frame 269/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 114.3ms\n",
      "video 1/1 (frame 270/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 106.5ms\n",
      "video 1/1 (frame 271/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 114.1ms\n",
      "video 1/1 (frame 272/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 106.0ms\n",
      "video 1/1 (frame 273/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 119.1ms\n",
      "video 1/1 (frame 274/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 111.0ms\n",
      "video 1/1 (frame 275/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 115.6ms\n",
      "video 1/1 (frame 276/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 111.0ms\n",
      "video 1/1 (frame 277/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 116.0ms\n",
      "video 1/1 (frame 278/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 109.0ms\n",
      "video 1/1 (frame 279/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 125.2ms\n",
      "video 1/1 (frame 280/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 128.5ms\n",
      "video 1/1 (frame 281/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 113.0ms\n",
      "video 1/1 (frame 282/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 107.7ms\n",
      "video 1/1 (frame 283/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 111.0ms\n",
      "video 1/1 (frame 284/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 132.1ms\n",
      "video 1/1 (frame 285/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 111.9ms\n",
      "video 1/1 (frame 286/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 115.8ms\n",
      "video 1/1 (frame 287/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 119.0ms\n",
      "video 1/1 (frame 288/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 116.3ms\n",
      "video 1/1 (frame 289/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 108.7ms\n",
      "video 1/1 (frame 290/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 111.3ms\n",
      "video 1/1 (frame 291/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 107.3ms\n",
      "video 1/1 (frame 292/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 117.0ms\n",
      "video 1/1 (frame 293/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 115.0ms\n",
      "video 1/1 (frame 294/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 111.0ms\n",
      "video 1/1 (frame 295/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 108.0ms\n",
      "video 1/1 (frame 296/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 116.0ms\n",
      "video 1/1 (frame 297/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 113.0ms\n",
      "video 1/1 (frame 298/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 108.0ms\n",
      "video 1/1 (frame 299/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 128.0ms\n",
      "video 1/1 (frame 300/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 129.6ms\n",
      "video 1/1 (frame 301/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 115.1ms\n",
      "video 1/1 (frame 302/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 113.9ms\n",
      "video 1/1 (frame 303/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 108.7ms\n",
      "video 1/1 (frame 304/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 122.0ms\n",
      "video 1/1 (frame 305/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 112.0ms\n",
      "video 1/1 (frame 306/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 111.5ms\n",
      "video 1/1 (frame 307/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 133.7ms\n",
      "video 1/1 (frame 308/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 116.0ms\n",
      "video 1/1 (frame 309/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 111.5ms\n",
      "video 1/1 (frame 310/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 107.0ms\n",
      "video 1/1 (frame 311/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 129.5ms\n",
      "video 1/1 (frame 312/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 106.3ms\n",
      "video 1/1 (frame 313/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 110.1ms\n",
      "video 1/1 (frame 314/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 114.5ms\n",
      "video 1/1 (frame 315/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 119.1ms\n",
      "video 1/1 (frame 316/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 1 person, 124.4ms\n",
      "video 1/1 (frame 317/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 121.1ms\n",
      "video 1/1 (frame 318/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 123.5ms\n",
      "video 1/1 (frame 319/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 127.0ms\n",
      "video 1/1 (frame 320/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 111.1ms\n",
      "video 1/1 (frame 321/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 106.5ms\n",
      "video 1/1 (frame 322/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 118.9ms\n",
      "video 1/1 (frame 323/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 117.0ms\n",
      "video 1/1 (frame 324/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 109.0ms\n",
      "video 1/1 (frame 325/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 111.0ms\n",
      "video 1/1 (frame 326/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 113.0ms\n",
      "video 1/1 (frame 327/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 116.5ms\n",
      "video 1/1 (frame 328/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 106.6ms\n",
      "video 1/1 (frame 329/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 130.1ms\n",
      "video 1/1 (frame 330/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 110.0ms\n",
      "video 1/1 (frame 331/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 120.0ms\n",
      "video 1/1 (frame 332/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 113.0ms\n",
      "video 1/1 (frame 333/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 108.0ms\n",
      "video 1/1 (frame 334/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 120.7ms\n",
      "video 1/1 (frame 335/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 118.1ms\n",
      "video 1/1 (frame 336/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 114.0ms\n",
      "video 1/1 (frame 337/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 119.5ms\n",
      "video 1/1 (frame 338/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 110.8ms\n",
      "video 1/1 (frame 339/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 113.0ms\n",
      "video 1/1 (frame 340/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 110.4ms\n",
      "video 1/1 (frame 341/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 113.4ms\n",
      "video 1/1 (frame 342/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 111.2ms\n",
      "video 1/1 (frame 343/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 125.0ms\n",
      "video 1/1 (frame 344/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 109.0ms\n",
      "video 1/1 (frame 345/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 117.1ms\n",
      "video 1/1 (frame 346/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 114.0ms\n",
      "video 1/1 (frame 347/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 123.2ms\n",
      "video 1/1 (frame 348/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 105.2ms\n",
      "video 1/1 (frame 349/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 108.6ms\n",
      "video 1/1 (frame 350/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 110.5ms\n",
      "video 1/1 (frame 351/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 115.0ms\n",
      "video 1/1 (frame 352/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 111.5ms\n",
      "video 1/1 (frame 353/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 116.5ms\n",
      "video 1/1 (frame 354/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 108.4ms\n",
      "video 1/1 (frame 355/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 121.4ms\n",
      "video 1/1 (frame 356/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 108.0ms\n",
      "video 1/1 (frame 357/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 121.0ms\n",
      "video 1/1 (frame 358/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 140.0ms\n",
      "video 1/1 (frame 359/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 135.6ms\n",
      "video 1/1 (frame 360/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 115.7ms\n",
      "video 1/1 (frame 361/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 109.0ms\n",
      "video 1/1 (frame 362/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 118.0ms\n",
      "video 1/1 (frame 363/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 108.0ms\n",
      "video 1/1 (frame 364/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 106.5ms\n",
      "video 1/1 (frame 365/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 106.1ms\n",
      "video 1/1 (frame 366/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 172.3ms\n",
      "video 1/1 (frame 367/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 118.9ms\n",
      "video 1/1 (frame 368/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 113.5ms\n",
      "video 1/1 (frame 369/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 110.0ms\n",
      "video 1/1 (frame 370/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 119.0ms\n",
      "video 1/1 (frame 371/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 106.0ms\n",
      "video 1/1 (frame 372/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 115.3ms\n",
      "video 1/1 (frame 373/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 103.5ms\n",
      "video 1/1 (frame 374/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 109.5ms\n",
      "video 1/1 (frame 375/375) c:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 117.5ms\n",
      "Speed: 3.2ms preprocess, 149.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "# Carga del modelo\n",
    "#model = YOLO('yolo11n.pt') #Contenedores\n",
    "#model = YOLO('yolo11n-seg.pt') #Mscaras\n",
    "model = YOLO('yolo11n-pose.pt')  #Pose\n",
    "\n",
    "#Para un vdeo \n",
    "filename = \"TGC23_PdH_C0056cut.mp4\"\n",
    "results = model(filename, show=True)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tarea 2: Comprobamos que tenemos el entorno preparado para usar CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos informacin de la GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Oct 28 22:59:45 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.94                 Driver Version: 560.94         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1070      WDDM  |   00000000:09:00.0  On |                  N/A |\n",
      "|  0%   49C    P8             15W /  210W |    2254MiB /   8192MiB |      4%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      2308    C+G   ...on\\wallpaper_engine\\wallpaper32.exe      N/A      |\n",
      "|    0   N/A  N/A      2824    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A      7808    C+G   ...on\\130.0.2849.52\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A      8828    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A      9224    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     10296    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A     10332    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A     10436    C+G   ...ne\\Binaries\\Win64\\EpicWebHelper.exe      N/A      |\n",
      "|    0   N/A  N/A     11784    C+G   ...paper_engine\\bin\\webwallpaper32.exe      N/A      |\n",
      "|    0   N/A  N/A     11976    C+G   ...Programs\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A     12396    C+G   ....0_x64__8wekyb3d8bbwe\\PhotosApp.exe      N/A      |\n",
      "|    0   N/A  N/A     13240    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     13688    C+G   ...al\\Discord\\app-1.0.9168\\Discord.exe      N/A      |\n",
      "|    0   N/A  N/A     15152    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A     15472    C+G   ...inaries\\Win64\\EpicGamesLauncher.exe      N/A      |\n",
      "|    0   N/A  N/A     15828    C+G   ...GeForce Experience\\NVIDIA Share.exe      N/A      |\n",
      "|    0   N/A  N/A     17052    C+G   ...a\\Local\\Programs\\Opera GX\\opera.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "nw = min([os.cpu_count()])\n",
    "print(nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.23  Python-3.9.20 torch-2.5.0 CUDA:0 (NVIDIA GeForce GTX 1070, 8192MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=C:/Users/varga/Documents/GitHub/VC-Practicas/P4/YOLODataset/dataset.yaml, epochs=300, time=None, patience=25, batch=-1, imgsz=416, save=True, save_period=-1, cache=False, device=0, workers=12, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLOv8n summary: 225 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=416 at 60.0% CUDA memory utilization.\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (NVIDIA GeForce GTX 1070) 8.00G total, 0.12G reserved, 0.06G allocated, 7.82G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
      "     3011043       3.462         0.161         38.01         73.02        (1, 3, 416, 416)                    list\n",
      "     3011043       6.924         0.182            29         41.01        (2, 3, 416, 416)                    list\n",
      "     3011043       13.85         0.268         29.01         62.01        (4, 3, 416, 416)                    list\n",
      "     3011043        27.7         0.514         31.01         40.01        (8, 3, 416, 416)                    list\n",
      "     3011043       55.39         0.967         40.01         50.03       (16, 3, 416, 416)                    list\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 83 for CUDA:0 4.83G/8.00G (60%) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\YOLODataset\\train\\labels... 66 images, 0 backgrounds, 0 corrupt: 100%|| 66/66 [00:00<00:00, 1319.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\YOLODataset\\train\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\YOLODataset\\val\\labels... 16 images, 0 backgrounds, 0 corrupt: 100%|| 16/16 [00:00<00:00, 940.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\YOLODataset\\val\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0006484375), 63 bias(decay=0.0)\n",
      "Image sizes 416 train, 416 val\n",
      "Using 12 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train\u001b[0m\n",
      "Starting training for 300 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/300      3.45G      5.537      10.98      4.326        148        416: 100%|| 1/1 [00:23<00:00, 23.85s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/300      3.45G      5.211      10.06      4.356        155        416: 100%|| 1/1 [00:03<00:00,  3.23s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/300      3.45G      5.276      9.211      4.648        166        416: 100%|| 1/1 [00:02<00:00,  2.76s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/300      3.45G      5.273      9.748       4.27        166        416: 100%|| 1/1 [00:02<00:00,  2.53s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/300      3.45G      5.177      7.885       4.37        167        416: 100%|| 1/1 [00:02<00:00,  2.55s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/300      3.45G      4.614      7.821      4.354        137        416: 100%|| 1/1 [00:02<00:00,  2.53s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/300      3.45G      4.092      6.989      4.395        134        416: 100%|| 1/1 [00:02<00:00,  2.53s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/300      3.45G      6.297      13.42      4.341        148        416: 100%|| 1/1 [00:02<00:00,  2.53s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/300      3.27G      5.168      8.341      4.298        161        416: 100%|| 1/1 [00:02<00:00,  2.62s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/300      3.48G       5.51      8.683      4.246        150        416: 100%|| 1/1 [00:02<00:00,  2.53s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/300      3.48G      4.591      8.978       4.31        136        416: 100%|| 1/1 [00:02<00:00,  2.54s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/300      3.48G      4.486      7.804      4.401        139        416: 100%|| 1/1 [00:02<00:00,  2.54s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/300      3.48G      4.537      6.588      4.267        155        416: 100%|| 1/1 [00:02<00:00,  2.56s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/300      3.48G      4.193       7.07      4.279        126        416: 100%|| 1/1 [00:02<00:00,  2.55s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/300      3.47G      5.285      8.767       4.41        119        416: 100%|| 1/1 [00:02<00:00,  2.56s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/300      3.48G      4.858      7.064      4.326        133        416: 100%|| 1/1 [00:02<00:00,  2.60s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/300      3.48G      4.894      7.982      4.232        157        416: 100%|| 1/1 [00:02<00:00,  2.57s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/300      3.48G      4.915      9.105      4.356        155        416: 100%|| 1/1 [00:02<00:00,  2.45s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/300      3.48G      4.473      7.433      4.223        159        416: 100%|| 1/1 [00:00<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/300      3.48G      4.642      7.432      4.184        146        416: 100%|| 1/1 [00:00<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/300      3.28G      4.046      7.365      4.275        169        416: 100%|| 1/1 [00:00<00:00,  1.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/300      3.48G      4.533      6.473      4.262        153        416: 100%|| 1/1 [00:00<00:00,  1.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/300      3.48G      5.163      6.591      4.067        159        416: 100%|| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/300      3.48G      4.674      6.748      4.045        137        416: 100%|| 1/1 [00:00<00:00,  1.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/300      3.48G      3.986      6.261      4.097        156        416: 100%|| 1/1 [00:00<00:00,  1.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/300      3.48G      4.172      7.164      4.032        147        416: 100%|| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/300      3.48G      4.446      7.219      4.024        170        416: 100%|| 1/1 [00:00<00:00,  1.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/300      3.48G      3.945      6.227      3.978        142        416: 100%|| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/300      3.48G      3.868      5.818      3.958        165        416: 100%|| 1/1 [00:00<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/300      3.48G      4.902       7.02      3.715        134        416: 100%|| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/300      3.48G      4.447      6.372      3.933        150        416: 100%|| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/300      3.48G       4.35      5.722      3.766        135        416: 100%|| 1/1 [00:00<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/300      3.48G      4.658      5.421      3.734        129        416: 100%|| 1/1 [00:00<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/300      3.48G      4.117      5.573      3.848        174        416: 100%|| 1/1 [00:00<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/300      3.48G      3.928      4.948      3.771        143        416: 100%|| 1/1 [00:00<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/300      3.48G      3.941      5.146      3.551        136        416: 100%|| 1/1 [00:00<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/300      3.48G       4.25      5.854      3.391        147        416: 100%|| 1/1 [00:00<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/300      3.48G      3.937      4.955       3.47        154        416: 100%|| 1/1 [00:00<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/300      3.48G      4.095      6.041      3.357        144        416: 100%|| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/300      3.48G      3.872      5.157      3.582        139        416: 100%|| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/300      3.48G      3.781      4.479        3.2        158        416: 100%|| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/300      3.48G      3.415      4.277      3.364        153        416: 100%|| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/300      3.48G      3.287      4.575      3.269        141        416: 100%|| 1/1 [00:00<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/300      3.48G      3.166       4.08      3.233        146        416: 100%|| 1/1 [00:00<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/300      3.48G      3.645      4.353      3.127        142        416: 100%|| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/300      3.48G       3.37      3.825      3.179        129        416: 100%|| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/300      3.48G      3.786      4.419      2.958        129        416: 100%|| 1/1 [00:00<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/300      3.48G      3.641      4.001       2.96        145        416: 100%|| 1/1 [00:00<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/300      3.48G      3.419      3.674      2.768        155        416: 100%|| 1/1 [00:00<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/300      3.48G      3.306      3.659      2.972        161        416: 100%|| 1/1 [00:00<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/300      3.48G      3.353       3.64       2.93        136        416: 100%|| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/300      3.48G      3.302      3.351       2.73        148        416: 100%|| 1/1 [00:00<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/300      3.48G      3.088       3.46      2.597        158        416: 100%|| 1/1 [00:00<00:00,  1.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/300      3.48G      3.309      3.352      2.871        160        416: 100%|| 1/1 [00:00<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     55/300      3.48G      2.809      2.904      2.575        151        416: 100%|| 1/1 [00:00<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     56/300      3.48G      3.015      3.212      2.796        129        416: 100%|| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     57/300      3.48G      3.572      3.212      2.763        137        416: 100%|| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     58/300      3.48G      3.082      2.966       2.62        165        416: 100%|| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     59/300      3.48G      3.382      3.274      2.835        146        416: 100%|| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     60/300      3.48G      3.004      3.086      2.569        142        416: 100%|| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     61/300      3.48G      3.183      3.362      2.552        157        416: 100%|| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     62/300      3.48G      2.972      3.134       2.62        157        416: 100%|| 1/1 [00:00<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     63/300      3.48G      3.096       3.43      2.555        151        416: 100%|| 1/1 [00:00<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     64/300      3.48G      3.125      3.107      2.478        137        416: 100%|| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     65/300      3.48G      2.842      2.706      2.297        145        416: 100%|| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     66/300      3.48G      2.835      2.926      2.549        133        416: 100%|| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     67/300      3.48G      2.857      2.997       2.33        124        416: 100%|| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     68/300      3.48G      2.829      2.918       2.48        136        416: 100%|| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     69/300      3.48G       2.75      2.699      2.434        152        416: 100%|| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     70/300      3.48G      2.745      2.481      2.194        150        416: 100%|| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     71/300      3.48G      2.831      2.544      2.195        148        416: 100%|| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     72/300      3.48G      2.581      2.637      2.417        145        416: 100%|| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     73/300      3.48G      2.803      2.568      2.095        163        416: 100%|| 1/1 [00:00<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     74/300      3.48G       2.74      2.605      2.168        152        416: 100%|| 1/1 [00:00<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     75/300      3.48G      2.587      2.419      1.971        121        416: 100%|| 1/1 [00:00<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     76/300      3.48G      2.722       2.46      2.179        143        416: 100%|| 1/1 [00:00<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     77/300      3.48G      2.655      2.331      2.182        146        416: 100%|| 1/1 [00:00<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     78/300      3.48G      2.354      2.332      1.988        146        416: 100%|| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     79/300      3.48G      2.486      2.328      2.065        127        416: 100%|| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     80/300      3.28G      2.505      2.249      1.923        154        416: 100%|| 1/1 [00:00<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     81/300      3.48G      2.541      2.301      1.902        143        416: 100%|| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     82/300      3.48G      2.644      2.276      2.055        139        416: 100%|| 1/1 [00:00<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     83/300      3.48G       2.37      2.059      1.837        147        416: 100%|| 1/1 [00:00<00:00,  1.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     84/300      3.48G      2.482      2.143      1.943        168        416: 100%|| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     85/300      3.48G      2.685       2.27      1.903        157        416: 100%|| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     86/300      3.48G      2.413       2.22      2.109        161        416: 100%|| 1/1 [00:00<00:00,  1.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     87/300      3.48G      2.414      2.134      1.816        171        416: 100%|| 1/1 [00:00<00:00,  1.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     88/300      3.48G       2.17      2.033      1.861        126        416: 100%|| 1/1 [00:00<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     89/300      3.48G      2.243      1.905      1.825        158        416: 100%|| 1/1 [00:00<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     90/300      3.48G      2.398      2.023      1.832        139        416: 100%|| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     91/300      3.48G      2.282      1.982      1.957        134        416: 100%|| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     92/300      3.48G      2.281      1.871      1.844        143        416: 100%|| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     93/300      3.48G       2.15      1.742      1.657        149        416: 100%|| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     94/300      3.48G      2.187      1.827      1.757        145        416: 100%|| 1/1 [00:00<00:00,  1.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     95/300      3.48G      2.261      1.841      1.726        157        416: 100%|| 1/1 [00:00<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     96/300      3.48G       2.09      1.707      1.723        153        416: 100%|| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     97/300      3.48G      2.168      1.816      1.844        153        416: 100%|| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     98/300      3.48G      2.094      1.728      1.837        141        416: 100%|| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     99/300      3.48G      2.163      1.988      2.015        142        416: 100%|| 1/1 [00:00<00:00,  1.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    100/300      3.48G      2.255      1.835      1.999        119        416: 100%|| 1/1 [00:00<00:00,  1.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    101/300      3.48G       2.29      1.845      1.829        154        416: 100%|| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    102/300      3.48G       2.04      1.781      1.759        155        416: 100%|| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    103/300      3.48G      1.986       1.75      1.711        132        416: 100%|| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    104/300      3.48G      2.116      1.807      1.844        130        416: 100%|| 1/1 [00:00<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    105/300      3.48G       2.27      1.698      1.768        130        416: 100%|| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    106/300      3.48G      2.004      1.871      1.777        129        416: 100%|| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    107/300      3.48G      2.096      1.874       1.82        135        416: 100%|| 1/1 [00:00<00:00,  1.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38   0.000992     0.0263    0.00465    0.00194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    108/300      3.48G      1.838       1.66      1.662        157        416: 100%|| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38    0.00104     0.0263    0.00207   0.000829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    109/300      3.48G      2.002      1.704      1.782        171        416: 100%|| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38   0.000966     0.0263    0.00297    0.00149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    110/300      3.48G      2.293       1.77      1.686        135        416: 100%|| 1/1 [00:00<00:00,  1.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.314     0.0263     0.0294    0.00518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    111/300      3.48G      1.995       1.65      1.642        127        416: 100%|| 1/1 [00:00<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.284     0.0263     0.0322     0.0119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    112/300      3.48G      2.019      1.651      1.539        172        416: 100%|| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38       0.44     0.0526     0.0432     0.0232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    113/300      3.48G      2.037      1.672      1.729        142        416: 100%|| 1/1 [00:00<00:00,  1.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.677     0.0526     0.0606     0.0355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    114/300      3.48G      2.149      1.584      1.589        150        416: 100%|| 1/1 [00:00<00:00,  1.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.645     0.0526     0.0622     0.0326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    115/300      3.48G      2.199        1.6       1.65        136        416: 100%|| 1/1 [00:00<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.535     0.0526     0.0641     0.0308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    116/300      3.48G      1.943      1.619       1.66        146        416: 100%|| 1/1 [00:00<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.708     0.0526     0.0664     0.0359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    117/300      3.48G       2.16      1.715      1.776        134        416: 100%|| 1/1 [00:00<00:00,  1.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.684     0.0526     0.0673     0.0278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    118/300      3.48G       2.04      1.534      1.619        142        416: 100%|| 1/1 [00:00<00:00,  1.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.449     0.0526     0.0685     0.0268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    119/300      3.48G      1.927      1.472      1.553        152        416: 100%|| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.471     0.0526     0.0682      0.025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    120/300      3.48G       1.94      1.491      1.515        140        416: 100%|| 1/1 [00:00<00:00,  1.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.345     0.0789     0.0713     0.0324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    121/300      3.48G      1.969      1.573      1.575        149        416: 100%|| 1/1 [00:00<00:00,  1.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.267     0.0789     0.0795     0.0404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    122/300      3.48G      1.945      1.508      1.605        165        416: 100%|| 1/1 [00:00<00:00,  1.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.295      0.105      0.081     0.0416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    123/300      3.48G      2.063      1.503      1.533        137        416: 100%|| 1/1 [00:00<00:00,  1.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.415      0.105     0.0953     0.0417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    124/300      3.48G      1.978      1.581      1.628        138        416: 100%|| 1/1 [00:00<00:00,  1.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.473      0.132      0.125     0.0511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    125/300      3.48G      1.949       1.52      1.504        139        416: 100%|| 1/1 [00:00<00:00,  1.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.546      0.132      0.133     0.0555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    126/300      3.48G      1.842       1.63      1.649        113        416: 100%|| 1/1 [00:00<00:00,  1.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.778      0.132      0.143     0.0567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    127/300      3.48G      1.698      1.475      1.466        137        416: 100%|| 1/1 [00:00<00:00,  1.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.891      0.132      0.153     0.0598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    128/300      3.48G      1.958      1.385      1.399        171        416: 100%|| 1/1 [00:00<00:00,  1.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38       0.71      0.132      0.154     0.0597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    129/300      3.48G       1.87      1.454      1.492        135        416: 100%|| 1/1 [00:00<00:00,  1.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.611      0.132      0.143     0.0521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    130/300      3.48G      1.808      1.395      1.514        148        416: 100%|| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.594      0.105       0.13     0.0498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    131/300      3.48G      1.828        1.3      1.485        149        416: 100%|| 1/1 [00:00<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.604      0.121      0.123     0.0418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    132/300      3.48G       1.91      1.332      1.496        149        416: 100%|| 1/1 [00:00<00:00,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.639      0.132      0.134     0.0585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    133/300      3.48G      1.748      1.301      1.453        130        416: 100%|| 1/1 [00:00<00:00,  1.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.845      0.132      0.148     0.0718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    134/300      3.48G      1.807      1.366      1.345        148        416: 100%|| 1/1 [00:00<00:00,  1.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.952      0.132      0.159      0.065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    135/300      3.48G      1.965      1.407      1.528        140        416: 100%|| 1/1 [00:00<00:00,  1.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.483      0.184      0.184     0.0692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    136/300      3.48G      1.866      1.274      1.416        168        416: 100%|| 1/1 [00:00<00:00,  1.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.539      0.184      0.192     0.0765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    137/300      3.48G      1.795      1.544      1.641        132        416: 100%|| 1/1 [00:00<00:00,  1.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.538      0.184      0.197     0.0722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    138/300      3.48G       1.87      1.557      1.615        143        416: 100%|| 1/1 [00:00<00:00,  1.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.966      0.158      0.186     0.0669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    139/300      3.48G      1.959       1.49       1.46        154        416: 100%|| 1/1 [00:00<00:00,  1.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.632      0.158       0.18     0.0735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    140/300      3.48G      1.835      1.372      1.457        135        416: 100%|| 1/1 [00:00<00:00,  1.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38       0.63      0.158      0.179      0.074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    141/300      3.48G      1.874      1.447      1.498        157        416: 100%|| 1/1 [00:00<00:00,  1.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.562      0.184      0.183     0.0768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    142/300      3.48G      1.898      1.398       1.56        142        416: 100%|| 1/1 [00:00<00:00,  1.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.574      0.184      0.186     0.0869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    143/300      3.48G      1.765      1.268      1.455        160        416: 100%|| 1/1 [00:00<00:00,  1.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.768      0.184      0.193     0.0811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    144/300      3.48G      1.664      1.294       1.44        131        416: 100%|| 1/1 [00:00<00:00,  1.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.843      0.184      0.192     0.0801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    145/300      3.48G      1.744      1.344      1.371        178        416: 100%|| 1/1 [00:00<00:00,  1.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38       0.84      0.184      0.195     0.0797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    146/300      3.48G      1.868      1.401        1.5        148        416: 100%|| 1/1 [00:00<00:00,  1.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.773      0.184      0.212     0.0979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    147/300      3.48G      1.764      1.418        1.5        144        416: 100%|| 1/1 [00:00<00:00,  1.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.617      0.212      0.213      0.103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    148/300      3.48G      1.813      1.271      1.492        169        416: 100%|| 1/1 [00:00<00:00,  1.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.657      0.211      0.211      0.108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    149/300      3.48G      1.679      1.179      1.328        144        416: 100%|| 1/1 [00:00<00:00,  1.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.613      0.211      0.205      0.104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    150/300      3.48G      1.641      1.172       1.39        137        416: 100%|| 1/1 [00:00<00:00,  1.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.811      0.184      0.206     0.0924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    151/300      3.48G      1.649      1.182      1.321        155        416: 100%|| 1/1 [00:00<00:00,  1.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.792      0.184      0.209     0.0935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    152/300      3.48G      1.598       1.14      1.269        150        416: 100%|| 1/1 [00:00<00:00,  1.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.847      0.184      0.215     0.0887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    153/300      3.48G      1.816      1.455      1.453        143        416: 100%|| 1/1 [00:00<00:00,  1.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.694      0.211      0.214      0.113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    154/300      3.48G      1.688      1.179       1.29        160        416: 100%|| 1/1 [00:00<00:00,  1.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.723      0.206      0.213      0.105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    155/300      3.48G      1.613      1.171      1.374        133        416: 100%|| 1/1 [00:00<00:00,  1.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.772      0.211      0.226      0.107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    156/300      3.48G      1.681      1.236      1.406        149        416: 100%|| 1/1 [00:00<00:00,  1.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.883      0.158      0.203     0.0914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    157/300      3.48G      1.559      1.197      1.356        139        416: 100%|| 1/1 [00:00<00:00,  1.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.878      0.184      0.212     0.0637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    158/300      3.48G      1.648      1.145      1.324        166        416: 100%|| 1/1 [00:00<00:00,  1.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.601      0.184      0.185     0.0672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    159/300      3.48G      1.563      1.114       1.31        138        416: 100%|| 1/1 [00:00<00:00,  1.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.606      0.184       0.17      0.073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    160/300      3.48G      1.686      1.289      1.314        167        416: 100%|| 1/1 [00:00<00:00,  1.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38       0.72      0.184      0.195     0.0759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    161/300      3.28G      1.793       1.33      1.302        152        416: 100%|| 1/1 [00:00<00:00,  1.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.867      0.184      0.208       0.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    162/300      3.48G      1.667      1.144       1.27        167        416: 100%|| 1/1 [00:00<00:00,  1.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.886      0.184      0.212     0.0725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    163/300      3.48G      1.503      1.076      1.287        144        416: 100%|| 1/1 [00:00<00:00,  1.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.866      0.184      0.215      0.075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    164/300      3.48G      1.551      1.156       1.32        137        416: 100%|| 1/1 [00:00<00:00,  1.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  7.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.629      0.237      0.234     0.0811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    165/300      3.48G      1.647      1.202      1.382        158        416: 100%|| 1/1 [00:00<00:00,  1.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.641      0.237      0.231      0.081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    166/300      3.48G      1.549      1.136      1.297        137        416: 100%|| 1/1 [00:00<00:00,  1.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.557      0.237      0.224     0.0937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    167/300      3.48G      1.638      1.202      1.325        126        416: 100%|| 1/1 [00:00<00:00,  1.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.471      0.237      0.213     0.0804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    168/300      3.48G      1.574      1.162      1.356        138        416: 100%|| 1/1 [00:00<00:00,  1.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.875      0.184      0.214     0.0846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    169/300      3.28G      1.714      1.157      1.386        173        416: 100%|| 1/1 [00:00<00:00,  1.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.707      0.211      0.221     0.0876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    170/300      3.48G      1.577        1.1      1.331        151        416: 100%|| 1/1 [00:00<00:00,  1.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.744      0.211      0.222      0.094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    171/300      3.48G      1.722      1.202      1.373        154        416: 100%|| 1/1 [00:00<00:00,  1.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.661      0.184      0.209      0.084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    172/300      3.48G       1.61       1.07      1.348        143        416: 100%|| 1/1 [00:00<00:00,  1.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.524      0.203        0.2     0.0671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    173/300      3.48G       1.64      1.068      1.352        145        416: 100%|| 1/1 [00:00<00:00,  1.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.502      0.184      0.195     0.0659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    174/300      3.48G      1.597      1.074      1.338        164        416: 100%|| 1/1 [00:00<00:00,  1.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.623      0.158      0.174     0.0732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    175/300      3.48G      1.756      1.182      1.349        137        416: 100%|| 1/1 [00:00<00:00,  1.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.741      0.211      0.237     0.0939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    176/300      3.48G      1.856       1.24      1.467        148        416: 100%|| 1/1 [00:00<00:00,  1.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.674      0.211      0.236     0.0894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    177/300      3.48G      1.857      1.251       1.39        166        416: 100%|| 1/1 [00:00<00:00,  1.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.704      0.211      0.238     0.0927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    178/300      3.48G      1.839      1.192      1.361        135        416: 100%|| 1/1 [00:00<00:00,  1.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.768      0.211      0.239     0.0935\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 25 epochs. Best results observed at epoch 153, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=25) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "178 epochs completed in 0.088 hours.\n",
      "Optimizer stripped from runs\\detect\\train\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs\\detect\\train\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs\\detect\\train\\weights\\best.pt...\n",
      "WARNING  validating an untrained model YAML will result in 0 mAP.\n",
      "Ultralytics 8.3.23  Python-3.9.20 torch-2.5.0 CUDA:0 (NVIDIA GeForce GTX 1070, 8192MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  8.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         38      0.692      0.211      0.214      0.111\n",
      "Speed: 0.1ms preprocess, 1.8ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"yolov8n.yaml\")\n",
    "# Train the model with adjusted settings\n",
    "results = model.train(data='C:/Users/varga/Documents/GitHub/VC-Practicas/P4/YOLODataset/dataset.yaml', \n",
    "                        epochs=300, \n",
    "                        imgsz=416, \n",
    "                        plots=True,\n",
    "                        patience= 25,\n",
    "                        batch=-1,\n",
    "                        workers=12,\n",
    "                        device=0,\n",
    "                        )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.23  Python-3.9.20 torch-2.5.0 CUDA:0 (NVIDIA GeForce GTX 1070, 8192MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "                   all         16         38      0.694      0.211      0.221      0.103\n",
      "Speed: 0.5ms preprocess, 10.0ms inference, 0.0ms loss, 12.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val\u001b[0m\n",
      " Learn more at https://docs.ultralytics.com/modes/val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\YOLODataset\\val\\labels.cache... 16 images, 0 backgrounds, 0 corrupt: 100%|| 16/16 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\varga\\Documents\\GitHub\\VC-Practicas\\P4\\YOLODataset\\val\\labels.cache... 16 images, 0 backgrounds, 0 corrupt: 100%|| 16/16 [00:00<?, ?it/s]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:05<00:00,  5.83s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:05<00:00,  5.83s/it]\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=val model=\"./runs/detect/train/weights/best.pt\" data=\"C:/Users/varga/Documents/GitHub/VC-Practicas/P4/YOLODataset/dataset.yaml\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desde cmara, deteccin con yolo11, modelo nano. Visualizacin propia con OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 2 persons, 6 cars, 1 stop sign, 44.0ms\n",
      "Speed: 3.0ms preprocess, 44.0ms inference, 55.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 384x416 1 Matricula, 35.0ms\n",
      "Speed: 2.0ms preprocess, 35.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "\n",
      "0: 320x416 (no detections), 40.0ms\n",
      "Speed: 2.0ms preprocess, 40.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 416x416 (no detections), 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "\n",
      "0: 288x416 (no detections), 40.2ms\n",
      "Speed: 1.0ms preprocess, 40.2ms inference, 0.9ms postprocess per image at shape (1, 3, 288, 416)\n",
      "\n",
      "0: 320x416 (no detections), 14.0ms\n",
      "Speed: 1.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 384x416 (no detections), 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "\n",
      "0: 480x640 4 persons, 3 cars, 1 bus, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 352x416 (no detections), 40.0ms\n",
      "Speed: 2.0ms preprocess, 40.0ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "\n",
      "0: 192x416 (no detections), 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 416)\n",
      "\n",
      "0: 416x224 (no detections), 34.0ms\n",
      "Speed: 2.0ms preprocess, 34.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 224)\n",
      "\n",
      "0: 480x640 1 car, 29.0ms\n",
      "Speed: 4.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 352x416 1 Matricula, 35.0ms\n",
      "Speed: 1.0ms preprocess, 35.0ms inference, 4.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "\n",
      "0: 480x640 1 person, 4 cars, 1 truck, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 160x416 (no detections), 36.0ms\n",
      "Speed: 1.0ms preprocess, 36.0ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 416)\n",
      "\n",
      "0: 416x352 (no detections), 35.0ms\n",
      "Speed: 1.0ms preprocess, 35.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 352)\n",
      "\n",
      "0: 224x416 1 Matricula, 37.6ms\n",
      "Speed: 2.0ms preprocess, 37.6ms inference, 2.0ms postprocess per image at shape (1, 3, 224, 416)\n",
      "\n",
      "0: 352x416 1 Matricula, 16.0ms\n",
      "Speed: 1.0ms preprocess, 16.0ms inference, 3.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "\n",
      "0: 480x640 2 cars, 15.6ms\n",
      "Speed: 3.0ms preprocess, 15.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 192x416 1 Matricula, 15.0ms\n",
      "Speed: 1.0ms preprocess, 15.0ms inference, 3.0ms postprocess per image at shape (1, 3, 192, 416)\n",
      "\n",
      "0: 288x416 (no detections), 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "\n",
      "0: 480x640 1 motorcycle, 15.0ms\n",
      "Speed: 2.9ms preprocess, 15.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9 cars, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 192x416 (no detections), 13.0ms\n",
      "Speed: 1.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 192, 416)\n",
      "\n",
      "0: 256x416 (no detections), 33.0ms\n",
      "Speed: 1.0ms preprocess, 33.0ms inference, 1.1ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 288x416 (no detections), 12.0ms\n",
      "Speed: 1.0ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 416)\n",
      "\n",
      "0: 128x416 (no detections), 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 128, 416)\n",
      "\n",
      "0: 224x416 (no detections), 13.0ms\n",
      "Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 416)\n",
      "\n",
      "0: 128x416 (no detections), 25.0ms\n",
      "Speed: 1.0ms preprocess, 25.0ms inference, 2.0ms postprocess per image at shape (1, 3, 128, 416)\n",
      "\n",
      "0: 128x416 (no detections), 24.0ms\n",
      "Speed: 2.0ms preprocess, 24.0ms inference, 1.0ms postprocess per image at shape (1, 3, 128, 416)\n",
      "\n",
      "0: 416x416 1 Matricula, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 3.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "\n",
      "0: 320x416 1 Matricula, 17.0ms\n",
      "Speed: 1.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 480x640 4 cars, 15.1ms\n",
      "Speed: 3.0ms preprocess, 15.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 256x416 1 Matricula, 14.0ms\n",
      "Speed: 1.0ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 352x416 (no detections), 13.0ms\n",
      "Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "\n",
      "0: 192x416 (no detections), 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 416)\n",
      "\n",
      "0: 224x416 (no detections), 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 416)\n",
      "\n",
      "0: 480x640 2 cars, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 192x416 1 Matricula, 14.9ms\n",
      "Speed: 2.0ms preprocess, 14.9ms inference, 3.0ms postprocess per image at shape (1, 3, 192, 416)\n",
      "\n",
      "0: 256x416 (no detections), 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 480x640 2 cars, 2 trucks, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 224x416 (no detections), 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 416)\n",
      "\n",
      "0: 192x416 (no detections), 19.0ms\n",
      "Speed: 2.0ms preprocess, 19.0ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 416)\n",
      "\n",
      "0: 480x640 4 cars, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 288x416 1 Matricula, 20.0ms\n",
      "Speed: 1.0ms preprocess, 20.0ms inference, 3.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "\n",
      "0: 320x416 (no detections), 14.0ms\n",
      "Speed: 1.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 416x256 (no detections), 39.0ms\n",
      "Speed: 2.0ms preprocess, 39.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 256)\n",
      "\n",
      "0: 384x416 (no detections), 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 416)\n",
      "\n",
      "0: 480x640 2 cars, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 160x416 (no detections), 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 416)\n",
      "\n",
      "0: 160x416 1 Matricula, 15.0ms\n",
      "Speed: 1.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 416)\n",
      "\n",
      "0: 480x640 5 cars, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 128x416 (no detections), 27.0ms\n",
      "Speed: 2.0ms preprocess, 27.0ms inference, 1.0ms postprocess per image at shape (1, 3, 128, 416)\n",
      "\n",
      "0: 160x416 (no detections), 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 416)\n",
      "\n",
      "0: 160x416 (no detections), 11.0ms\n",
      "Speed: 1.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 416)\n",
      "\n",
      "0: 352x416 (no detections), 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "\n",
      "0: 256x416 (no detections), 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 480x640 6 cars, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 288x416 1 Matricula, 13.0ms\n",
      "Speed: 1.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "\n",
      "0: 160x416 (no detections), 16.0ms\n",
      "Speed: 1.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 160, 416)\n",
      "\n",
      "0: 96x416 (no detections), 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 416)\n",
      "\n",
      "0: 320x416 (no detections), 16.0ms\n",
      "Speed: 1.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 192x416 (no detections), 13.0ms\n",
      "Speed: 1.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 192, 416)\n",
      "\n",
      "0: 128x416 (no detections), 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 128, 416)\n",
      "\n",
      "0: 480x640 4 cars, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 416x416 (no detections), 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "\n",
      "0: 160x416 1 Matricula, 12.0ms\n",
      "Speed: 1.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 160, 416)\n",
      "\n",
      "0: 160x416 1 Matricula, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 3.0ms postprocess per image at shape (1, 3, 160, 416)\n",
      "\n",
      "0: 256x416 (no detections), 14.0ms\n",
      "Speed: 1.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 480x640 3 cars, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 192x416 1 Matricula, 13.0ms\n",
      "Speed: 1.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 192, 416)\n",
      "\n",
      "0: 320x416 (no detections), 14.0ms\n",
      "Speed: 1.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 416x384 (no detections), 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "\n",
      "0: 480x640 2 cars, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 128x416 1 Matricula, 27.0ms\n",
      "Speed: 2.0ms preprocess, 27.0ms inference, 3.0ms postprocess per image at shape (1, 3, 128, 416)\n",
      "\n",
      "0: 288x416 (no detections), 13.0ms\n",
      "Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "\n",
      "0: 480x640 2 cars, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 352x416 1 Matricula, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 3.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "\n",
      "0: 416x416 2 Matriculas, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 4.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "\n",
      "0: 480x640 2 persons, 5 cars, 1 truck, 1 stop sign, 7.8ms\n",
      "Speed: 3.2ms preprocess, 7.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 416x416 2 Matriculas, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "\n",
      "0: 320x416 (no detections), 12.0ms\n",
      "Speed: 1.0ms preprocess, 12.0ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 128x416 (no detections), 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 128, 416)\n",
      "\n",
      "0: 288x416 (no detections), 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "\n",
      "0: 416x384 (no detections), 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "\n",
      "0: 480x640 3 persons, 6 cars, 1 truck, 1 stop sign, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 352x416 (no detections), 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "\n",
      "0: 224x416 (no detections), 13.0ms\n",
      "Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 416)\n",
      "\n",
      "0: 416x416 1 Matricula, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 3.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "\n",
      "0: 416x384 (no detections), 16.0ms\n",
      "Speed: 1.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "\n",
      "0: 416x384 (no detections), 11.0ms\n",
      "Speed: 1.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "\n",
      "0: 416x256 (no detections), 13.0ms\n",
      "Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 256)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Carga del modelo\n",
    "model = YOLO('yolov8n.pt')\n",
    "customModel = YOLO(\"./runs/detect/train/weights/best.pt\")\n",
    "\n",
    "# Nombre de las distintas clases\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "\n",
    "folder_path = \"./images1/\"\n",
    "\n",
    "image_files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "\n",
    "reader = easyocr.Reader(['es'])\n",
    "\n",
    "def encontrar_matricula_yolo(car_img):\n",
    "    results = customModel(car_img)\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes: \n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            cv2.rectangle(car_img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            matricula = car_img[y1:y2, x1:x2]\n",
    "            # Usar EasyOCR para leer la matrcula\n",
    "            matricula_resultados = reader.readtext(matricula, allowlist=\"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789-.\")\n",
    "            if matricula_resultados:\n",
    "                matricula_text = matricula_resultados[0][-2]\n",
    "                return matricula_text\n",
    "            \n",
    "    return \"\" \n",
    "\n",
    "for image_file in image_files:\n",
    "    # Lee la imagen desde la carpeta\n",
    "    img = cv2.imread(os.path.join(folder_path, image_file))\n",
    "    target_size = (800, 600)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    \n",
    "    # Perform inference on an image\n",
    "    results = model(img)\n",
    "\n",
    "    # Para cada deteccin\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            # Identificacin de la matrcula para coches\n",
    "            if classNames[int(box.cls[0])] == \"car\":\n",
    "                # Dibuja un rectngulo negro alrededor del coche\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 0), 2)\n",
    "\n",
    "                car = img[y1:y2, x1:x2]\n",
    "                # Pasar esta mitad inferior a la funcin encontrar_matricula\n",
    "                #matricula_text= \n",
    "                matricula_text = encontrar_matricula_yolo(car)\n",
    "\n",
    "                cv2.putText(img, matricula_text, (x1, y1 + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "                \n",
    "\n",
    "        # Muestra la imagen con las detecciones\n",
    "        cv2.imshow('Image', img)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "# Cierra la ventana al finalizar\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 18.0ms\n",
      "Speed: 2.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.0ms\n",
      "Speed: 1.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.6ms\n",
      "Speed: 1.0ms preprocess, 12.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.0ms\n",
      "Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.0ms\n",
      "Speed: 1.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.0ms\n",
      "Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.0ms\n",
      "Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.0ms\n",
      "Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.0ms\n",
      "Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.0ms\n",
      "Speed: 1.0ms preprocess, 14.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "# Carga del modelo, descarga en disco si no est presente en la carpeta\n",
    "model = YOLO('yolo11n.pt') #Contenedores\n",
    "\n",
    "# Etiqueta de las distintas clases\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "\n",
    "\n",
    "# Captura desde la webcam\n",
    "vid = cv2.VideoCapture(0)\n",
    "  \n",
    "while(True):      \n",
    "    # fotograma a fotograma\n",
    "    ret, img = vid.read()\n",
    "  \n",
    "    # si hay imagen vlida\n",
    "    if ret:  \n",
    "        # Detecta en la imagen\n",
    "        results = model(img, stream=True)\n",
    "        \n",
    "        # Para cada deteccin\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                # Contenedor\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "                \n",
    "                # Confianza\n",
    "                confidence = math.ceil((box.conf[0]*100))/100\n",
    "                print(\"Confianza --->\",confidence)\n",
    "\n",
    "                # Clase\n",
    "                cls = int(box.cls[0])\n",
    "                print(\"Clase -->\", classNames[cls])\n",
    "\n",
    "                # Convierte identificador numrico de clase a un color RGB\n",
    "                escala = int((cls / len(classNames)) * 255 * 3)\n",
    "                if escala >= 255*2:\n",
    "                    R = 255\n",
    "                    G = 255\n",
    "                    B = escala - 255*2\n",
    "                else:\n",
    "                    if escala >= 255:\n",
    "                        R = 255\n",
    "                        G = escala - 255\n",
    "                        B = 0\n",
    "                    else:\n",
    "                        R = escala\n",
    "                        G = 0\n",
    "                        B = 0\n",
    "\n",
    "                # Dibuja el contenedor y clase\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (R, G, B), 3)\n",
    "                cv2.putText(img, classNames[cls] , [x1, y1], cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, B), 2)\n",
    "\n",
    "        # Muestra fotograma\n",
    "        cv2.imshow('Vid', img)\n",
    "    \n",
    "    # Detenemos pulsado ESC\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "  \n",
    "# Libera el objeto de captura\n",
    "vid.release()\n",
    "# Destruye ventanas\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguimiento. Requiere instalar lap con pip install lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# Carga del modelo, descarga en disco si no est presente en la carpeta\n",
    "model = YOLO('yolo11n.pt') #Contenedores\n",
    "\n",
    "# Etiqueta de las distintas clases\n",
    "classNames = [\"person\", \"bicycle\", \"car\"]\n",
    "\n",
    "\n",
    "# Captura desde la webcam\n",
    "vid = cv2.VideoCapture(0)\n",
    "track_history = defaultdict(lambda: [])\n",
    "  \n",
    "while(True):      \n",
    "    # fotograma a fotograma\n",
    "    ret, img = vid.read()\n",
    "  \n",
    "    # si hay imagen vlida\n",
    "    if ret:  \n",
    "        # Seguimiento, con persistencia entre fotogramas\n",
    "        results = model.track(img, persist=True, classes = [0,1,2])\n",
    "\n",
    "        if 0:\n",
    "            if results is not None:\n",
    "                print(results[0])\n",
    "                boxes = results[0].boxes.xywh.cpu()\n",
    "                track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "                annotated_frame = results[0].plot()\n",
    "                for box, track_id in zip(boxes, track_ids):\n",
    "                    x, y, w, h = box\n",
    "                    track = track_history[track_id]\n",
    "                    track.append((float(x), float(y)))\n",
    "                    if len(track) > 30:\n",
    "                        track.pop(0)\n",
    "                    points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n",
    "                    cv2.polylines(annotated_frame, [points], isClosed=False, color=(230, 230, 230), thickness=10)\n",
    "                cv2.imshow(\"YOLO11 Tracking\", annotated_frame)\n",
    "                if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                    break\n",
    "        \n",
    "\n",
    "        \n",
    "        # Para cada deteccin\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                # Contenedor\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "\n",
    "                #Etiqueta de seguimiento\n",
    "                if box.id is not None:\n",
    "                    track_id = str(int(box.id[0].tolist()))\n",
    "                else:\n",
    "                    track_id = ''\n",
    "                \n",
    "                # Confianza\n",
    "                confidence = math.ceil((box.conf[0]*100))/100\n",
    "                print(\"Confianza --->\",confidence)\n",
    "\n",
    "                # Clase\n",
    "                cls = int(box.cls[0])\n",
    "                print(\"Clase -->\", classNames[cls])\n",
    "\n",
    "                # Convierte identificador numrico de clase a un color RGB\n",
    "                escala = int((cls / len(classNames)) * 255 * 3)\n",
    "                if escala >= 255*2:\n",
    "                    R = 255\n",
    "                    G = 255\n",
    "                    B = escala - 255*2\n",
    "                else:\n",
    "                    if escala >= 255:\n",
    "                        R = 255\n",
    "                        G = escala - 255\n",
    "                        B = 0\n",
    "                    else:\n",
    "                        R = escala\n",
    "                        G = 0\n",
    "                        B = 0\n",
    "\n",
    "                # Dibuja el contenedor y clase\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (R, G, B), 3)\n",
    "                cv2.putText(img, track_id + ' ' + classNames[cls] , [x1, y1], cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, B), 2)\n",
    "\n",
    "        # Muestra fotograma\n",
    "        cv2.imshow('Vid', img)\n",
    "    \n",
    "    # Detenemos pulsado ESC\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "  \n",
    "# Libera el objeto de captura\n",
    "vid.release()\n",
    "# Destruye ventanas\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intregracin con seguimiento (tracking)\n",
    "!!!!!!!!!Nota: he tenido que bajar a la versin de python 3.9.5 e instalar lap con pip install lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga del modelo\n",
    "model = YOLO('yolov8n.pt') #Contenedores\n",
    "#model = YOLO('yolov8n-seg.pt') #Mscaras\n",
    "#model = YOLO('yolov8n-pose.pt')  #Pose\n",
    "\n",
    "#Para un vdeo \n",
    "filename = \"TGC23_PdH_C0056cut.mp4\"\n",
    "results = model.track(source=filename, show=True)  # BoT-SORT tracker (por defecto)\n",
    "#results = model.track(source=filename, show=True, tracker=\"bytetrack.yaml\")  # ByteTrack tracker\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconocimiento de caracteres tras instalar pytesseract y tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tesseract\n",
    "import cv2\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "\n",
    "# Previamente debes descargar los ejecutables\n",
    "# Si la ruta de Tesseract no est en el PATH, ruta al ejecutable\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:/Program Files/Tesseract-OCR/tesseract'\n",
    "\n",
    "# Lenguajes disponibles\n",
    "print(pytesseract.get_languages(config=''))\n",
    "\n",
    "#Cargo imagen y ocnvierto a RGB\n",
    "img = cv2.imread('ocr_test.tif') \n",
    "\n",
    "if img is not None:\n",
    "    #Convierte a RGB antes de procesar\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    #Texto localizado\n",
    "    print(pytesseract.image_to_string(img))\n",
    "\n",
    "    #Texto y localizacin en imagen de cada palabra\n",
    "    d = pytesseract.image_to_data(img_rgb, output_type=Output.DICT)\n",
    "\n",
    "    n_boxes = len(d['text'])\n",
    "    for i in range(n_boxes):\n",
    "        #Nivel de confianza\n",
    "        if int(d['conf'][i]) > 60:\n",
    "            text = d['text'][i]\n",
    "            conf = d['conf'][i]\n",
    "            (x, y, w, h) = (d['left'][i], d['top'][i], d['width'][i], d['height'][i])\n",
    "            img = cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "            print(f'Texto: {text} ({conf:.2f}%)\\nContenedor: {x,y,x+w,y+h}')\n",
    "\n",
    "    cv2.imshow('img', img_rgb)\n",
    "    cv2.waitKey(-1)\n",
    "\n",
    "   \n",
    "\n",
    "else:\n",
    "    print('Error de imagen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconocimiento de caracteres tras instalar easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "\n",
    "#Carga del modelo de lengua\n",
    "reader = easyocr.Reader(['es']) \n",
    "\n",
    "#Reconocimiento de una imagen\n",
    "res = reader.readtext('ocr_test.tif')\n",
    "\n",
    "for (bbox, text, prob) in res:\n",
    "    # Coordenadas en orden \n",
    "    (top_left, top_right, bottom_right, bottom_left) = bbox\n",
    "    print(f'\\nTexto: {text}\\nProbabilidad: {prob:.2f}\\nContenedor: {tuple(map(int, top_left)),tuple(map(int, bottom_right))}')\n",
    "\n",
    "\n",
    "#Con restriccin de caracteres reconocibles\n",
    "#result = reader.readtext('toy.tif', allowlist ='0123456789')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
