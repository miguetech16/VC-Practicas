{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pygame\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "from PIL import Image, ImageSequence\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "from moviepy import VideoFileClip\n",
    "\n",
    "\n",
    "# Inicializa los módulos de Mediapipe\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Configuración del video de referencia\n",
    "dance_video = 'dance_video.mp4'\n",
    "audio_output_path = \"audio.mp3\"\n",
    "\n",
    "play_button = cv2.imread(\"./assets/play.png\", cv2.IMREAD_UNCHANGED)\n",
    "logo = cv2.imread(\"./assets/logo.png\", cv2.IMREAD_UNCHANGED)\n",
    "score_screen = cv2.imread(\"./assets/score.png\", cv2.IMREAD_UNCHANGED)\n",
    "skeleton_on= cv2.imread(\"./assets/skeleton.png\", cv2.IMREAD_UNCHANGED)\n",
    "skeleton_off= cv2.imread(\"./assets/skeleton_off.png\", cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# Variable global para controlar el tiempo de espera\n",
    "last_toggle_time = 0  # Almacena el tiempo del último toggle\n",
    "TOGGLE_DELAY = 1  # Tiempo de espera en segundos\n",
    "\n",
    "# Configuración\n",
    "process_every_n_frames = 30\n",
    "toggle_squeleton=  False\n",
    "\n",
    "# Bandera para detener los hilos\n",
    "stop_threads = False  \n",
    "\n",
    "#puntuación\n",
    "score= 8000\n",
    "\n",
    "best_score= 0 \n",
    "\n",
    "# Crear un índice para cambiar entre los frames del GIF\n",
    "gif_index = 0\n",
    "# Convertir el GIF en una lista de frames de imágenes\n",
    "gif_frames = []\n",
    "\n",
    "#0 pantalla inicio 1 juego 2 puntuación\n",
    "game_mode= 0\n",
    "\n",
    "\n",
    "\n",
    "def overlay_image(frame, overlay, x, y, resizex=None, resizey=None):\n",
    "    \"\"\"\n",
    "    Superpone una imagen sobre un frame en las coordenadas (x, y).\n",
    "    \"\"\"\n",
    "\n",
    "    # Redimensionar el overlay si es necesario\n",
    "    if resizex and resizey:\n",
    "        overlay = cv2.resize(overlay, (resizex, resizey))\n",
    "    \n",
    "    overlay_height, overlay_width = overlay.shape[:2]\n",
    "\n",
    "    # Verificar los límites del frame\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "    if y + overlay_height > frame_height or x + overlay_width > frame_width:\n",
    "        raise ValueError(\"El overlay excede los límites del frame.\")\n",
    "\n",
    "    # Manejar el canal alfa si está presente\n",
    "    alpha_overlay = None\n",
    "    if overlay.shape[2] == 4:\n",
    "        alpha_overlay = overlay[:, :, 3] / 255.0  # Normaliza el canal alfa\n",
    "        overlay = overlay[:, :, :3]  # Elimina el canal alfa para la mezcla\n",
    "\n",
    "    # Seleccionar la región de interés (ROI) en el frame\n",
    "    roi = frame[y:y+overlay_height, x:x+overlay_width]\n",
    "\n",
    "    # Mezcla usando el canal alfa (si existe)\n",
    "    if alpha_overlay is not None:\n",
    "        for c in range(3):  # Mezcla cada canal (B, G, R)\n",
    "            roi[:, :, c] = (alpha_overlay * overlay[:, :, c] +\n",
    "                            (1 - alpha_overlay) * roi[:, :, c])\n",
    "    else:\n",
    "        # Sin canal alfa, simplemente reemplaza los píxeles\n",
    "        frame[y:y+overlay_height, x:x+overlay_width] = overlay\n",
    "\n",
    "# Función para actualizar el índice del GIF y obtener el siguiente frame\n",
    "def get_next_gif_frame():\n",
    "    global gif_index\n",
    "    if gif_index < len(gif_frames):  # Aumenta el índice solo si hay fotogramas disponibles\n",
    "        frame = cv2.resize(gif_frames[gif_index], (100, 100))\n",
    "        gif_index += 1\n",
    "        return frame\n",
    "    return None  # Devuelve None después de completar el GIF\n",
    "\n",
    "\n",
    "def change_gif(score):\n",
    "    global gif_index\n",
    "    global gif\n",
    "    global gif_frames\n",
    "    \n",
    "    gif_index=0\n",
    "    # Cargar el archivo GIF usando PIL\n",
    "    if score==100:\n",
    "        gif_path = \"./assets/perfect.gif\"\n",
    "    elif score==50:\n",
    "        gif_path = \"./assets/good.gif\"\n",
    "    else:\n",
    "        gif_path = \"./assets/fail.gif\"  # Ruta al archivo GIF\n",
    "\n",
    "    gif = Image.open(gif_path)\n",
    "    # Convertir el GIF en una lista de frames de imágenes\n",
    "    gif_frames = []\n",
    "    for frame in ImageSequence.Iterator(gif):\n",
    "        frame = frame.convert(\"RGBA\")  # Asegurarse de que el GIF tenga un canal alfa\n",
    "        gif_frames.append(np.array(frame))\n",
    "        \n",
    "\n",
    "def calcular_distancia_escala(puntos):\n",
    "    hombro_izquierdo = puntos[11]\n",
    "    hombro_derecho = puntos[12]\n",
    "    return np.linalg.norm(np.array([hombro_izquierdo[\"x\"], hombro_izquierdo[\"y\"]]) -\n",
    "                          np.array([hombro_derecho[\"x\"], hombro_derecho[\"y\"]]))\n",
    "\n",
    "def calcular_similitud(puntos1, puntos2, escala1, escala2):\n",
    "    if not puntos1 or not puntos2 or len(puntos1) != len(puntos2):\n",
    "        return 0\n",
    "\n",
    "    distancias = []\n",
    "    for p1, p2 in zip(puntos1, puntos2):\n",
    "        p1_escalado = np.array([p1[\"x\"] / escala1, p1[\"y\"] / escala1, p1[\"z\"] / escala1])\n",
    "        p2_escalado = np.array([p2[\"x\"] / escala2, p2[\"y\"] / escala2, p2[\"z\"] / escala2])\n",
    "        distancias.append(np.linalg.norm(p1_escalado - p2_escalado))\n",
    "\n",
    "    return np.mean(distancias)\n",
    "\n",
    "def obtener_puntos_por_frame(json_data, frame_buscado):\n",
    "    for entrada in json_data:\n",
    "        if entrada[\"frame\"] == frame_buscado:\n",
    "            return entrada[\"puntos\"]\n",
    "    return None\n",
    "\n",
    "def puntuacion(json_file, frame_buscado, results_cam):\n",
    "    puntos_referencia = obtener_puntos_por_frame(json_file, frame_buscado)\n",
    "    if puntos_referencia:\n",
    "        puntos_usuario = [\n",
    "            {\"x\": lm.x, \"y\": lm.y, \"z\": lm.z, \"visibility\": lm.visibility}\n",
    "            for lm in results_cam.pose_landmarks.landmark\n",
    "        ]\n",
    "\n",
    "        escala_referencia = calcular_distancia_escala(puntos_referencia)\n",
    "        escala_usuario = calcular_distancia_escala(puntos_usuario)\n",
    "\n",
    "        similitud = calcular_similitud(puntos_referencia, puntos_usuario, escala_referencia, escala_usuario)\n",
    "\n",
    "        if similitud < 5:\n",
    "            change_gif(100)\n",
    "            return 100\n",
    "        elif similitud < 10:\n",
    "            change_gif(50)\n",
    "            return 50\n",
    "        else:\n",
    "            change_gif(0)\n",
    "            return 0\n",
    "    return 0\n",
    "\n",
    "\n",
    "start_music = True\n",
    "def process_video(cap_video, video_queue, video_frame_rate, frame_width, frame_height, puntos_video_referencia):\n",
    "    global stop_threads, game_mode, start_music, score, best_score\n",
    "\n",
    "    linea= 0\n",
    "    \n",
    "    while cap_video.isOpened() and not stop_threads:\n",
    "        if game_mode == 1:\n",
    "            linea= 0\n",
    "            if start_music:\n",
    "                pygame.mixer.music.play()\n",
    "                cap_video.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "                start_music = False\n",
    "            current_time = pygame.mixer.music.get_pos() / 1_000\n",
    "            current_frame_index = int(current_time * video_frame_rate)\n",
    "\n",
    "            cap_video.set(cv2.CAP_PROP_POS_FRAMES, current_frame_index)\n",
    "            ret_video, frame_video = cap_video.read()\n",
    "            if not ret_video:\n",
    "                game_mode = 2\n",
    "                continue\n",
    "\n",
    "            frame_rgb = cv2.cvtColor(frame_video, cv2.COLOR_BGR2RGB)\n",
    "            frame_rgb = cv2.resize(frame_rgb, (frame_width, frame_height))  # Reducir tamaño\n",
    "\n",
    "            gif_frame = get_next_gif_frame()\n",
    "            if gif_frame is not None:\n",
    "                overlay_image(frame_rgb, gif_frame, 0, 0)\n",
    "            \n",
    "            if toggle_squeleton==True:\n",
    "                puntos_referencia = obtener_puntos_por_frame(puntos_video_referencia, current_frame_index)\n",
    "                # Dibujar puntos y conexiones en el video de referencia\n",
    "                if puntos_referencia:\n",
    "                    for conexion in mp_pose.POSE_CONNECTIONS:\n",
    "                        inicio = puntos_referencia[conexion[0]]\n",
    "                        fin = puntos_referencia[conexion[1]]\n",
    "                        inicio_px = (int(inicio[\"x\"] * frame_width), int(inicio[\"y\"] * frame_height))\n",
    "                        fin_px = (int(fin[\"x\"] * frame_width), int(fin[\"y\"] * frame_height))\n",
    "                        cv2.line(frame_rgb, inicio_px, fin_px, (255, 0, 0), 2)\n",
    "\n",
    "                    for punto in puntos_referencia:\n",
    "                        px = (int(punto[\"x\"] * frame_width), int(punto[\"y\"] * frame_height))\n",
    "                        cv2.circle(frame_rgb, px, 5, (0, 255, 0), -1)\n",
    "\n",
    "        elif game_mode == 0:\n",
    "            frame_rgb = cv2.cvtColor(logo, cv2.COLOR_BGR2RGB)\n",
    "            frame_rgb = cv2.resize(frame_rgb, (frame_width, frame_height)) \n",
    "        elif game_mode == 2:\n",
    "\n",
    "            if best_score < score:\n",
    "                best_score = score\n",
    "            frame_rgb = cv2.cvtColor(score_screen, cv2.COLOR_BGR2RGB)\n",
    "            frame_rgb = cv2.resize(frame_rgb, (frame_width, frame_height)) \n",
    "            cv2.putText(frame_rgb, f'Puntuacion: {best_score}', (110, 90),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "            cv2.putText(frame_rgb, f'Mejor puntuacion: {score}', (110, 125),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "            if linea < 440*score/20000 and linea < 439:\n",
    "                linea+=1\n",
    "            cv2.rectangle(frame_rgb,(110, 140),(550 ,170),(0,0,0),-1)\n",
    "            cv2.rectangle(frame_rgb,(111, 141),(110 + linea ,169),(255,0,0),-1)\n",
    "\n",
    "        video_queue.put(frame_rgb)\n",
    "\n",
    "    cap_video.release()\n",
    "\n",
    "\n",
    "def process_camera(cap_camera, camera_queue, puntos_video_referencia, video_frame_rate, frame_width, frame_height, cap_video):\n",
    "    global stop_threads, game_mode, score, toggle_squeleton, last_toggle_time, TOGGLE_DELAY, start_music\n",
    "\n",
    "    # Coordenadas del botón (ajusta según sea necesario)\n",
    "    button_x, button_y = 50, 100\n",
    "    button_width, button_height = 80, 80\n",
    "\n",
    "    # Coordenadas del esqueleto (ajusta según sea necesario)\n",
    "    skeleton_x, skeleton_y = 50, 200\n",
    "    skeleton_width, skeleton_height = 80, 120\n",
    "    \n",
    "    pose = None\n",
    "    hands = None\n",
    "    \n",
    "    while cap_camera.isOpened() and not stop_threads:\n",
    "        ret_camera, frame_camera = cap_camera.read()\n",
    "\n",
    "        if not ret_camera:\n",
    "            break\n",
    "\n",
    "        # Initialize the frame that will be processed\n",
    "        frame_camera = cv2.flip(frame_camera, 1)\n",
    "        frame_camera = cv2.resize(frame_camera, (frame_width, frame_height))\n",
    "        rgb_frame_cam = cv2.cvtColor(frame_camera, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if game_mode == 1:\n",
    "            # Initialize Pose model if it's not already initialized\n",
    "            if pose is None:\n",
    "                pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "            current_time = pygame.mixer.music.get_pos() / 1_000\n",
    "            current_frame_index = int(current_time * video_frame_rate)\n",
    "\n",
    "            if toggle_squeleton == True:\n",
    "                results_cam = pose.process(rgb_frame_cam)\n",
    "                if results_cam.pose_landmarks:\n",
    "\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        rgb_frame_cam, results_cam.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                        mp_drawing.DrawingSpec(color=(0, 255, 255), thickness=2, circle_radius=2),\n",
    "                        mp_drawing.DrawingSpec(color=(255, 0, 255), thickness=2, circle_radius=2)\n",
    "                    )\n",
    "                    if current_frame_index % process_every_n_frames == 0:\n",
    "                        score += puntuacion(puntos_video_referencia, current_frame_index, results_cam)\n",
    "\n",
    "\n",
    "            elif current_frame_index % process_every_n_frames == 0:\n",
    "                # Process with Pose model\n",
    "                results_cam = pose.process(rgb_frame_cam)\n",
    "                print(current_frame_index)\n",
    "                if results_cam.pose_landmarks:\n",
    "                    score += puntuacion(puntos_video_referencia, current_frame_index, results_cam)\n",
    "\n",
    "                \n",
    "            cv2.putText(rgb_frame_cam, f'Puntuacion: {score}', (10, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            \n",
    "        else:\n",
    "            # Initialize Hands model if it's not already initialized\n",
    "            if hands is None:\n",
    "                hands = mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.5)\n",
    "                \n",
    "            # Process with Hands model\n",
    "            results_cam = hands.process(rgb_frame_cam)\n",
    "\n",
    "            # Dibujar el botón de \"play\"\n",
    "            overlay_image(rgb_frame_cam, play_button, button_x, button_y, button_width, button_height)\n",
    "\n",
    "            if toggle_squeleton:\n",
    "                overlay_image(rgb_frame_cam, skeleton_on, skeleton_x, skeleton_y, skeleton_width, skeleton_height)\n",
    "            else:\n",
    "                overlay_image(rgb_frame_cam, skeleton_off, skeleton_x, skeleton_y, skeleton_width, skeleton_height)\n",
    "\n",
    "        \n",
    "            if results_cam.multi_hand_landmarks:\n",
    "                for hand_landmarks in results_cam.multi_hand_landmarks:\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        rgb_frame_cam, hand_landmarks, mp_hands.HAND_CONNECTIONS,  # Use HAND_CONNECTIONS instead of POSE_CONNECTIONS\n",
    "                        mp_drawing.DrawingSpec(color=(0, 255, 255), thickness=2, circle_radius=2),\n",
    "                        mp_drawing.DrawingSpec(color=(255, 0, 255), thickness=2, circle_radius=2)\n",
    "                    )\n",
    "                \n",
    "                # Check if the hand is inside the play button area\n",
    "                for landmark in hand_landmarks.landmark:\n",
    "                    hand_x = int(landmark.x * frame_width)\n",
    "                    hand_y = int(landmark.y * frame_height)\n",
    "\n",
    "                    if button_x <= hand_x <= button_x + button_width and button_y <= hand_y <= button_y + button_height:\n",
    "                        game_mode = 1  # Switch to game mode\n",
    "                        score = 0\n",
    "                        start_music = True\n",
    "                        pose = None  # Reset the Pose model when switching to game mode\n",
    "                    if skeleton_x <= hand_x <= skeleton_x + skeleton_width and skeleton_y <= hand_y <= skeleton_y + skeleton_height:\n",
    "                        current_time = time.time()  # Obtiene el tiempo actual\n",
    "                        if current_time - last_toggle_time > TOGGLE_DELAY:  # Verifica si ha pasado suficiente tiempo\n",
    "                            toggle_squeleton = not toggle_squeleton  # Cambia el modo de juego\n",
    "                            last_toggle_time = current_time  # Actualiza el tiempo del último toggle\n",
    "\n",
    "        # Put the processed frame into the queue\n",
    "        camera_queue.put(rgb_frame_cam)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def jugar_con_puntos(json_file, video_path):\n",
    "    global stop_threads\n",
    "\n",
    "    with open(json_file, 'r') as f:\n",
    "        puntos_video_referencia = json.load(f)\n",
    "\n",
    "    pygame.init()\n",
    "    pygame.mixer.music.load(audio_output_path)\n",
    "\n",
    "    cap_video = cv2.VideoCapture(video_path)\n",
    "    cap_camera = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap_video.isOpened() or not cap_camera.isOpened():\n",
    "        print(\"Error: No se pudo abrir el video o la cámara.\")\n",
    "        return\n",
    "\n",
    "    frame_width = 640  # Reducir a la mitad\n",
    "    frame_height = 360  # Reducir a la mitad\n",
    "    video_frame_rate = cap_video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    screen_width = frame_width * 2  # Doblar para mostrar video + cámara\n",
    "    screen_height = frame_height\n",
    "    screen = pygame.display.set_mode((screen_width, screen_height))  # Usar dimensiones reducidas\n",
    "\n",
    "    video_queue = Queue()\n",
    "    camera_queue = Queue()\n",
    "\n",
    "    video_thread = Thread(target=process_video, args=(cap_video, video_queue, video_frame_rate, frame_width, frame_height, puntos_video_referencia))\n",
    "    camera_thread = Thread(target=process_camera, args=(cap_camera, camera_queue, puntos_video_referencia, video_frame_rate, frame_width, frame_height, cap_video))\n",
    "\n",
    "    video_thread.start()\n",
    "    camera_thread.start()\n",
    "\n",
    "    while video_thread.is_alive() or camera_thread.is_alive():\n",
    "        if not video_queue.empty():\n",
    "            frame_rgb = video_queue.get()\n",
    "            current_image = pygame.image.frombuffer(frame_rgb.tobytes(), frame_rgb.shape[1::-1], \"RGB\")\n",
    "            screen.blit(current_image, (0, 0))\n",
    "\n",
    "        if not camera_queue.empty():\n",
    "            frame_camera_rgb = camera_queue.get()\n",
    "            frame_camera_surface = pygame.image.frombuffer(frame_camera_rgb.tobytes(), frame_camera_rgb.shape[1::-1], \"RGB\")\n",
    "            screen.blit(frame_camera_surface, (frame_width, 0))\n",
    "\n",
    "        pygame.display.flip()\n",
    "\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                stop_threads = True\n",
    "                video_thread.join()\n",
    "                camera_thread.join()\n",
    "                cap_video.release()\n",
    "                cap_camera.release()\n",
    "                pygame.quit()\n",
    "                return\n",
    "\n",
    "    stop_threads = True\n",
    "    video_thread.join()\n",
    "    camera_thread.join()\n",
    "    cap_video.release()\n",
    "    cap_camera.release()\n",
    "    pygame.quit()\n",
    "\n",
    "# Función para extraer puntos de referencia y guardarlos en un archivo JSON\n",
    "def extraer_y_guardar_puntos(video_path, output_file):\n",
    "    puntos_video_referencia = []\n",
    "    # Cargar el video y extraer el audio\n",
    "    video_clip = VideoFileClip(video_path)\n",
    "    video_clip.audio.write_audiofile(audio_output_path)\n",
    "\n",
    "    print(\"Audio extraído y guardado en:\", audio_output_path)\n",
    "    print(\"Se va a procesar el video, este proceso puede durar varios minutos...\")\n",
    "\n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        video_cap = cv2.VideoCapture(video_path)\n",
    "        while True:\n",
    "            ret_vid, frame_vid = video_cap.read()\n",
    "            if not ret_vid:\n",
    "                break\n",
    "\n",
    "            # Obtén el índice del frame actual\n",
    "            frame_index = int(video_cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "\n",
    "            rgb_frame_vid = cv2.cvtColor(frame_vid, cv2.COLOR_BGR2RGB)\n",
    "            results_vid = pose.process(rgb_frame_vid)\n",
    "\n",
    "            if results_vid.pose_landmarks:\n",
    "                puntos = []\n",
    "                for landmark in results_vid.pose_landmarks.landmark:\n",
    "                    puntos.append({\n",
    "                        \"x\": landmark.x,\n",
    "                        \"y\": landmark.y,\n",
    "                        \"z\": landmark.z,\n",
    "                        \"visibility\": landmark.visibility\n",
    "                    })\n",
    "\n",
    "                # Agrega los puntos junto con el índice del frame al resultado\n",
    "                puntos_video_referencia.append({\n",
    "                    \"frame\": frame_index,\n",
    "                    \"puntos\": puntos\n",
    "                })\n",
    "\n",
    "        video_cap.release()\n",
    "\n",
    "    # Guarda los puntos en un archivo JSON\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(puntos_video_referencia, f)\n",
    "\n",
    "    print(f\"Puntos de referencia guardados en {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    modo = input(\"Seleccione modo: 'extraer' para guardar puntos o 'jugar' para comparar: \")\n",
    "\n",
    "    if modo == 'extraer':\n",
    "        extraer_y_guardar_puntos(dance_video, 'puntos_referencia.json')\n",
    "    elif modo == 'jugar':\n",
    "        jugar_con_puntos('puntos_referencia.json', dance_video)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_VC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
