{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Inicializa MediaPipe\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# Configura la cámara\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Verifica si la cámara está disponible\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: No se puede acceder a la cámara.\")\n",
    "    exit()\n",
    "\n",
    "# Inicia el modelo de detección de pose\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"No se pudo leer el cuadro de la cámara.\")\n",
    "            break\n",
    "\n",
    "        \n",
    "        # Convierte la imagen de BGR a RGB\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Procesa la imagen para detectar poses\n",
    "        results = pose.process(rgb_frame)\n",
    "\n",
    "        # Dibuja las anotaciones de pose en la imagen original\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2)\n",
    "            )\n",
    "\n",
    "        # Muestra la imagen procesada\n",
    "        cv2.imshow('Skeleton Detection', frame)\n",
    "\n",
    "        # Salir con la tecla 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Libera los recursos\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "\n",
    "# Inicializa los módulos de Mediapipe\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Configura la cámara y el video\n",
    "cap = cv2.VideoCapture(0)  # Cámara en vivo\n",
    "video_cap = cv2.VideoCapture('dance_video.mp4')  # Video del archivo\n",
    "\n",
    "# Variable para medir el tiempo\n",
    "start_time = time.time()\n",
    "\n",
    "# Inicia el modelo de detección de pose\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while True:\n",
    "        # Captura cuadro del video\n",
    "        ret_vid, frame_vid = video_cap.read()\n",
    "        if not ret_vid:\n",
    "            print(\"Se alcanzó el final del video.\")\n",
    "            video_cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # Reinicia el video\n",
    "            ret_vid, frame_vid = video_cap.read()\n",
    "\n",
    "        frame_vid = cv2.resize(frame_vid, None, fx=0.5, fy=0.5)\n",
    "        # Procesa el video\n",
    "        rgb_frame_vid = cv2.cvtColor(frame_vid, cv2.COLOR_BGR2RGB)\n",
    "        results_vid = pose.process(rgb_frame_vid)\n",
    "\n",
    "        if results_vid.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame_vid, results_vid.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(0, 255, 255), thickness=2, circle_radius=2)\n",
    "            )\n",
    "\n",
    "        # Captura los puntos cada 30 segundos\n",
    "        current_time = time.time()\n",
    "        if current_time - start_time >= 30:\n",
    "\n",
    "            # Imprime los puntos del video en la terminal\n",
    "            if results_vid.pose_landmarks:\n",
    "                print(\"Puntos detectados (Video):\")\n",
    "                for id, landmark in enumerate(results_vid.pose_landmarks.landmark):\n",
    "                    print(f\"Punto {id}: (x: {landmark.x}, y: {landmark.y}, z: {landmark.z}, visibilidad: {landmark.visibility})\")\n",
    "                print(\"\\n---\\n\")\n",
    "\n",
    "            # Reinicia el contador de tiempo\n",
    "            start_time = current_time\n",
    "\n",
    "        # Muestra las imágenes procesadas\n",
    "        cv2.imshow('Skeleton Detection (Video)', frame_vid)\n",
    "\n",
    "        # Termina el bucle si se presiona la tecla 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Libera los recursos\n",
    "cap.release()\n",
    "video_cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Inicializa los módulos de Mediapipe\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Configuración del video de referencia\n",
    "dance_video = 'dance_video.mp4'\n",
    "\n",
    "# Función para extraer puntos de referencia y guardarlos en un archivo JSON\n",
    "def extraer_y_guardar_puntos(video_path, output_file):\n",
    "    puntos_video_referencia = []\n",
    "\n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        video_cap = cv2.VideoCapture(video_path)\n",
    "        while True:\n",
    "            ret_vid, frame_vid = video_cap.read()\n",
    "            if not ret_vid:\n",
    "                break\n",
    "\n",
    "            rgb_frame_vid = cv2.cvtColor(frame_vid, cv2.COLOR_BGR2RGB)\n",
    "            results_vid = pose.process(rgb_frame_vid)\n",
    "\n",
    "            if results_vid.pose_landmarks:\n",
    "                puntos = []\n",
    "                for landmark in results_vid.pose_landmarks.landmark:\n",
    "                    puntos.append({\n",
    "                        \"x\": landmark.x,\n",
    "                        \"y\": landmark.y,\n",
    "                        \"z\": landmark.z,\n",
    "                        \"visibility\": landmark.visibility\n",
    "                    })\n",
    "                puntos_video_referencia.append(puntos)\n",
    "\n",
    "        video_cap.release()\n",
    "\n",
    "    # Guarda los puntos en un archivo JSON\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(puntos_video_referencia, f)\n",
    "\n",
    "    print(f\"Puntos de referencia guardados en {output_file}\")\n",
    "\n",
    "# Función para calcular la distancia relativa entre puntos clave\n",
    "def calcular_distancia_escala(puntos):\n",
    "    \"\"\"\n",
    "    Calcula una medida de escala basada en la distancia entre los hombros\n",
    "    (puntos 11 y 12 en Mediapipe Pose).\n",
    "    \"\"\"\n",
    "    hombro_izquierdo = puntos[11]\n",
    "    hombro_derecho = puntos[12]\n",
    "    return np.linalg.norm(np.array([hombro_izquierdo[\"x\"], hombro_izquierdo[\"y\"]]) -\n",
    "                          np.array([hombro_derecho[\"x\"], hombro_derecho[\"y\"]]))\n",
    "\n",
    "# Código para jugar comparando los puntos guardados\n",
    "def jugar_con_puntos(json_file, video_path):\n",
    "    # Carga los puntos del archivo JSON\n",
    "    with open(json_file, 'r') as f:\n",
    "        puntos_video_referencia = json.load(f)\n",
    "\n",
    "    cap = cv2.VideoCapture(0)  # Cámara en vivo\n",
    "    video_cap = cv2.VideoCapture(video_path)  # Video de referencia\n",
    "\n",
    "    # Obtén la tasa de fotogramas por segundo (FPS) del video de referencia\n",
    "    fps_video = video_cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_duration = 1 / fps_video  # Duración de cada cuadro en segundos\n",
    "\n",
    "    def calcular_similitud(puntos1, puntos2, escala1, escala2):\n",
    "        \"\"\"\n",
    "        Calcula la similitud entre dos poses ajustando las coordenadas por sus escalas relativas.\n",
    "        \"\"\"\n",
    "        if not puntos1 or not puntos2 or len(puntos1) != len(puntos2):\n",
    "            return 0\n",
    "\n",
    "        distancias = []\n",
    "        for p1, p2 in zip(puntos1, puntos2):\n",
    "            p1_escalado = np.array([p1[\"x\"] / escala1, p1[\"y\"] / escala1, p1[\"z\"] / escala1])\n",
    "            p2_escalado = np.array([p2[\"x\"] / escala2, p2[\"y\"] / escala2, p2[\"z\"] / escala2])\n",
    "            distancias.append(np.linalg.norm(p1_escalado - p2_escalado))\n",
    "\n",
    "        return np.mean(distancias)\n",
    "\n",
    "    current_time = 0\n",
    "    while True:\n",
    "        # Leer cuadro del video de referencia\n",
    "        ret_vid, frame_vid = video_cap.read()\n",
    "        if not ret_vid:\n",
    "            video_cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # Reinicia el video\n",
    "            ret_vid, frame_vid = video_cap.read()\n",
    "            current_time = 0\n",
    "\n",
    "        # Calcular el índice del JSON basado en el tiempo transcurrido\n",
    "        frame_idx = int(current_time * fps_video)\n",
    "        if frame_idx < len(puntos_video_referencia):\n",
    "            puntos_referencia = puntos_video_referencia[frame_idx]\n",
    "\n",
    "            # Dibujar puntos y conexiones en el video de referencia\n",
    "            altura, ancho, _ = frame_vid.shape\n",
    "            for conexion in mp_pose.POSE_CONNECTIONS:\n",
    "                inicio = puntos_referencia[conexion[0]]\n",
    "                fin = puntos_referencia[conexion[1]]\n",
    "                inicio_px = (int(inicio[\"x\"] * ancho), int(inicio[\"y\"] * altura))\n",
    "                fin_px = (int(fin[\"x\"] * ancho), int(fin[\"y\"] * altura))\n",
    "                cv2.line(frame_vid, inicio_px, fin_px, (255, 0, 0), 2)\n",
    "\n",
    "            for punto in puntos_referencia:\n",
    "                px = (int(punto[\"x\"] * ancho), int(punto[\"y\"] * altura))\n",
    "                cv2.circle(frame_vid, px, 5, (0, 255, 0), -1)\n",
    "\n",
    "        # Leer cuadro de la cámara en vivo\n",
    "        ret_cam, frame_cam = cap.read()\n",
    "        if not ret_cam:\n",
    "            print(\"No se puede acceder a la cámara.\")\n",
    "            break\n",
    "\n",
    "        rgb_frame_cam = cv2.cvtColor(frame_cam, cv2.COLOR_BGR2RGB)\n",
    "        with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "            results_cam = pose.process(rgb_frame_cam)\n",
    "\n",
    "            if results_cam.pose_landmarks:\n",
    "                puntos_usuario = [\n",
    "                    {\"x\": lm.x, \"y\": lm.y, \"z\": lm.z, \"visibility\": lm.visibility}\n",
    "                    for lm in results_cam.pose_landmarks.landmark\n",
    "                ]\n",
    "\n",
    "                if frame_idx < len(puntos_video_referencia):\n",
    "                    escala_referencia = calcular_distancia_escala(puntos_referencia)\n",
    "                    escala_usuario = calcular_distancia_escala(puntos_usuario)\n",
    "\n",
    "                    similitud = calcular_similitud(puntos_referencia, puntos_usuario, escala_referencia, escala_usuario)\n",
    "\n",
    "                    if similitud < 0.1:\n",
    "                        puntuacion = 100\n",
    "                    elif similitud < 0.2:\n",
    "                        puntuacion = 50\n",
    "                    else:\n",
    "                        puntuacion = 0\n",
    "\n",
    "                    cv2.putText(frame_cam, f'Puntuacion: {puntuacion}', (10, 50),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            if results_cam.pose_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    frame_cam, results_cam.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                    mp_drawing.DrawingSpec(color=(0, 255, 255), thickness=2, circle_radius=2),\n",
    "                    mp_drawing.DrawingSpec(color=(255, 0, 255), thickness=2, circle_radius=2)\n",
    "                )\n",
    "\n",
    "        # Mostrar ambos cuadros\n",
    "        combinado = np.hstack((cv2.resize(frame_vid, (640, 480)), cv2.resize(frame_cam, (640, 480))))\n",
    "        cv2.imshow('Comparacion: Video vs Usuario', combinado)\n",
    "\n",
    "        # Incrementar el tiempo actual según la duración de cada cuadro\n",
    "        current_time += frame_duration\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    video_cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Ejemplo de uso\n",
    "if __name__ == \"__main__\":\n",
    "    modo = input(\"Seleccione modo: 'extraer' para guardar puntos o 'jugar' para comparar: \")\n",
    "\n",
    "    if modo == 'extraer':\n",
    "        extraer_y_guardar_puntos(dance_video, 'puntos_referencia.json')\n",
    "    elif modo == 'jugar':\n",
    "        jugar_con_puntos('puntos_referencia.json', dance_video)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 180\u001b[0m\n\u001b[0;32m    178\u001b[0m     extraer_y_guardar_puntos(dance_video, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpuntos_referencia.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m modo \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjugar\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 180\u001b[0m     \u001b[43mjugar_con_puntos\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpuntos_referencia.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdance_video\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 169\u001b[0m, in \u001b[0;36mjugar_con_puntos\u001b[1;34m(json_file, video_path)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 169\u001b[0m \u001b[43mcap\u001b[49m\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    170\u001b[0m video_cap\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    171\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cap' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Inicializa los módulos de Mediapipe\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Configuración del video de referencia\n",
    "dance_video = 'dance_video.mp4'\n",
    "\n",
    "\n",
    "\n",
    "# Función para calcular la distancia relativa entre puntos clave\n",
    "def calcular_distancia_escala(puntos):\n",
    "    \"\"\"\n",
    "    Calcula una medida de escala basada en la distancia entre los hombros\n",
    "    (puntos 11 y 12 en Mediapipe Pose).\n",
    "    \"\"\"\n",
    "    hombro_izquierdo = puntos[11]\n",
    "    hombro_derecho = puntos[12]\n",
    "    return np.linalg.norm(np.array([hombro_izquierdo[\"x\"], hombro_izquierdo[\"y\"]]) -\n",
    "                          np.array([hombro_derecho[\"x\"], hombro_derecho[\"y\"]]))\n",
    "\n",
    "# Código para jugar comparando los puntos guardados\n",
    "\n",
    "def jugar_con_puntos(json_file, video_path):\n",
    "    # Carga los puntos del archivo JSON\n",
    "    with open(json_file, 'r') as f:\n",
    "        puntos_video_referencia = json.load(f)\n",
    "\n",
    "    #cap = cv2.VideoCapture(0)  # Cámara en vivo\n",
    "    video_cap = cv2.VideoCapture(video_path)  # Video de referencia\n",
    "\n",
    "    # def calcular_similitud(puntos1, puntos2, escala1, escala2):\n",
    "    #     \"\"\"\n",
    "    #     Calcula la similitud entre dos poses ajustando las coordenadas por sus escalas relativas.\n",
    "    #     \"\"\"\n",
    "    #     if not puntos1 or not puntos2 or len(puntos1) != len(puntos2):\n",
    "    #         return 0\n",
    "\n",
    "    #     distancias = []\n",
    "    #     for p1, p2 in zip(puntos1, puntos2):\n",
    "    #         p1_escalado = np.array([p1[\"x\"] / escala1, p1[\"y\"] / escala1, p1[\"z\"] / escala1])\n",
    "    #         p2_escalado = np.array([p2[\"x\"] / escala2, p2[\"y\"] / escala2, p2[\"z\"] / escala2])\n",
    "    #         distancias.append(np.linalg.norm(p1_escalado - p2_escalado))\n",
    "\n",
    "    #     return np.mean(distancias)\n",
    "\n",
    "    frame_idx = 0\n",
    "\n",
    "    while True:\n",
    "        # Leer cuadro del video de referencia\n",
    "        if frame_idx < len(puntos_video_referencia):\n",
    "            referencia = puntos_video_referencia[frame_idx]\n",
    "            puntos_referencia = referencia[\"puntos\"]\n",
    "            frame_index = referencia[\"frame\"]\n",
    "\n",
    "            # Posicionar el video en el frame correspondiente\n",
    "            video_cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index)\n",
    "            ret_vid, frame_vid = video_cap.read()\n",
    "\n",
    "            if not ret_vid:\n",
    "                break\n",
    "\n",
    "            # Dibujar puntos y conexiones en el video de referencia\n",
    "            altura, ancho, _ = frame_vid.shape\n",
    "            for conexion in mp_pose.POSE_CONNECTIONS:\n",
    "                inicio = puntos_referencia[conexion[0]]\n",
    "                fin = puntos_referencia[conexion[1]]\n",
    "                inicio_px = (int(inicio[\"x\"] * ancho), int(inicio[\"y\"] * altura))\n",
    "                fin_px = (int(fin[\"x\"] * ancho), int(fin[\"y\"] * altura))\n",
    "                cv2.line(frame_vid, inicio_px, fin_px, (255, 0, 0), 2)\n",
    "\n",
    "            for punto in puntos_referencia:\n",
    "                px = (int(punto[\"x\"] * ancho), int(punto[\"y\"] * altura))\n",
    "                cv2.circle(frame_vid, px, 5, (0, 255, 0), -1)\n",
    "\n",
    "        # Leer cuadro de la cámara en vivo\n",
    "        # ret_cam, frame_cam = cap.read()\n",
    "        # if not ret_cam:\n",
    "        #     print(\"No se puede acceder a la cámara.\")\n",
    "        #     break\n",
    "\n",
    "        # frame_cam = cv2.resize(frame_cam, None, fx=0.5, fy=0.5)\n",
    "        # rgb_frame_cam = cv2.cvtColor(frame_cam, cv2.COLOR_BGR2RGB)\n",
    "        # with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        #     results_cam = pose.process(rgb_frame_cam)\n",
    "\n",
    "        #     if results_cam.pose_landmarks:\n",
    "        #         puntos_usuario = [\n",
    "        #             {\"x\": lm.x, \"y\": lm.y, \"z\": lm.z, \"visibility\": lm.visibility}\n",
    "        #             for lm in results_cam.pose_landmarks.landmark\n",
    "        #         ]\n",
    "\n",
    "                # if frame_idx < len(puntos_video_referencia):\n",
    "                #     escala_referencia = calcular_distancia_escala(puntos_referencia)\n",
    "                #     escala_usuario = calcular_distancia_escala(puntos_usuario)\n",
    "\n",
    "                #     similitud = calcular_similitud(puntos_referencia, puntos_usuario, escala_referencia, escala_usuario)\n",
    "\n",
    "                #     if similitud < 0.1:\n",
    "                #         puntuacion = 100\n",
    "                #     elif similitud < 0.2:\n",
    "                #         puntuacion = 50\n",
    "                #     else:\n",
    "                #         puntuacion = 0\n",
    "\n",
    "                #     cv2.putText(frame_cam, f'Puntuacion: {puntuacion}', (10, 50),\n",
    "                #                 cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            # if results_cam.pose_landmarks:\n",
    "            #     mp_drawing.draw_landmarks(\n",
    "            #         frame_cam, results_cam.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "            #         mp_drawing.DrawingSpec(color=(0, 255, 255), thickness=2, circle_radius=2),\n",
    "            #         mp_drawing.DrawingSpec(color=(255, 0, 255), thickness=2, circle_radius=2)\n",
    "            #     )\n",
    "\n",
    "        # Mostrar ambos cuadros\n",
    "        # combinado = np.hstack((cv2.resize(frame_vid, (640, 480)), cv2.resize(frame_cam, (640, 480))))\n",
    "\n",
    "        cv2.imshow('Comparacion: Video vs Usuario', frame_vid)\n",
    "\n",
    "        frame_idx += 1\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    video_cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Ejemplo de uso\n",
    "if __name__ == \"__main__\":\n",
    "    modo = input(\"Seleccione modo: 'extraer' para guardar puntos o 'jugar' para comparar: \")\n",
    "\n",
    "    if modo == 'extraer':\n",
    "        extraer_y_guardar_puntos(dance_video, 'puntos_referencia.json')\n",
    "    elif modo == 'jugar':\n",
    "        jugar_con_puntos('puntos_referencia.json', dance_video)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: []\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.03846546651225\n",
      "29.13448370694829\n",
      "8.457150036738447\n",
      "5.787539773231634\n",
      "5.89521938704435\n",
      "5.970348683331194\n",
      "5.384230527295914\n",
      "4.498148092636044\n",
      "4.768854737994984\n",
      "5.015178541974257\n",
      "5.589208446900982\n",
      "5.984069798576098\n",
      "5.194977309336598\n",
      "4.353297254685842\n",
      "5.7779338298319995\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pygame\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "\n",
    "# Inicializa los módulos de Mediapipe\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Configuración del video de referencia\n",
    "dance_video = 'dance_video.mp4'\n",
    "\n",
    "\n",
    "# Función para calcular la distancia relativa entre puntos clave\n",
    "def calcular_distancia_escala(puntos):\n",
    "    \"\"\"\n",
    "    Calcula una medida de escala basada en la distancia entre los hombros\n",
    "    (puntos 11 y 12 en Mediapipe Pose).\n",
    "    \"\"\"\n",
    "    hombro_izquierdo = puntos[11]\n",
    "    hombro_derecho = puntos[12]\n",
    "    return np.linalg.norm(np.array([hombro_izquierdo[\"x\"], hombro_izquierdo[\"y\"]]) -\n",
    "                          np.array([hombro_derecho[\"x\"], hombro_derecho[\"y\"]]))\n",
    "\n",
    "\n",
    "def calcular_similitud(puntos1, puntos2, escala1, escala2):\n",
    "        \"\"\"\n",
    "        Calcula la similitud entre dos poses ajustando las coordenadas por sus escalas relativas.\n",
    "        \"\"\"\n",
    "        if not puntos1 or not puntos2 or len(puntos1) != len(puntos2):\n",
    "            return 0\n",
    "\n",
    "        distancias = []\n",
    "        for p1, p2 in zip(puntos1, puntos2):\n",
    "            p1_escalado = np.array([p1[\"x\"] / escala1, p1[\"y\"] / escala1, p1[\"z\"] / escala1])\n",
    "            p2_escalado = np.array([p2[\"x\"] / escala2, p2[\"y\"] / escala2, p2[\"z\"] / escala2])\n",
    "            distancias.append(np.linalg.norm(p1_escalado - p2_escalado))\n",
    "\n",
    "        return np.mean(distancias)\n",
    "\n",
    "\n",
    "\n",
    "def obtener_puntos_por_frame(json_data, frame_buscado):\n",
    "    # Buscar el frame en el JSON\n",
    "    for entrada in json_data:\n",
    "        if entrada[\"frame\"] == frame_buscado:\n",
    "            return entrada[\"puntos\"]\n",
    "    return None  # Si no se encuentra el frame\n",
    "\n",
    "\n",
    "\n",
    "def puntuacion(json_file, frame_buscado,results_cam, frame_cam):\n",
    "    puntos_referencia = obtener_puntos_por_frame (json_file, frame_buscado)\n",
    "    if(puntos_referencia):\n",
    "        puntos_usuario = [\n",
    "                    {\"x\": lm.x, \"y\": lm.y, \"z\": lm.z, \"visibility\": lm.visibility}\n",
    "                    for lm in results_cam.pose_landmarks.landmark\n",
    "                ]\n",
    "        \n",
    "        escala_referencia = calcular_distancia_escala(puntos_referencia)\n",
    "        escala_usuario = calcular_distancia_escala(puntos_usuario)\n",
    "\n",
    "        similitud = calcular_similitud(puntos_referencia, puntos_usuario, escala_referencia, escala_usuario)\n",
    "\n",
    "        print(similitud)\n",
    "    \n",
    "        if similitud < 5:\n",
    "            puntuacion = 100\n",
    "        elif similitud < 10:\n",
    "            puntuacion = 50\n",
    "        else:\n",
    "            puntuacion = 0\n",
    "\n",
    "        return(puntuacion)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "def jugar_con_puntos(json_file, video_path):\n",
    "\n",
    "    with open(json_file, 'r') as f:\n",
    "        puntos_video_referencia = json.load(f)\n",
    "\n",
    "    # Inicializar Pygame\n",
    "    pygame.init()\n",
    "\n",
    "    # Cargar y reproducir el archivo de audio\n",
    "    audio_file = 'audio_extraido.mp3'  # Reemplaza con la ruta a tu archivo de audio\n",
    "    pygame.mixer.music.load(audio_file)\n",
    "    pygame.mixer.music.play()\n",
    "\n",
    "    # Cargar el video usando OpenCV\n",
    "    cap_video = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Verifica si se pudo abrir el archivo de video\n",
    "    if not cap_video.isOpened():\n",
    "        print(\"Error: No se pudo abrir el archivo de video.\")\n",
    "        exit()\n",
    "\n",
    "    # Obtener las dimensiones del video (ancho y alto)\n",
    "    frame_width = int(cap_video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Configuración de la ventana de Pygame\n",
    "    screen_width = frame_width * 2  # Pantalla con el doble de ancho (video + cámara)\n",
    "    screen_height = frame_height  # Mantener la altura igual\n",
    "    screen = pygame.display.set_mode((screen_width, screen_height))  # Tamaño de la ventana\n",
    "\n",
    "    # Obtener la tasa de fotogramas del video (FPS)\n",
    "    video_frame_rate = cap_video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # Inicialización de variables\n",
    "    last_frame_index = -1\n",
    "\n",
    "    # Configura la cámara\n",
    "    cap_camera = cv2.VideoCapture(0)\n",
    "\n",
    "    # Verifica si la cámara está disponible\n",
    "    if not cap_camera.isOpened():\n",
    "        print(\"Error: No se puede acceder a la cámara.\")\n",
    "        exit()\n",
    "\n",
    "    score=0\n",
    "\n",
    "    # Inicia el modelo de detección de pose\n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "\n",
    "    \n",
    "        while cap_video.isOpened() and cap_camera.isOpened():\n",
    "            # Obtiene el tiempo actual de la música en segundos\n",
    "            current_time = pygame.mixer.music.get_pos() / 1_000  # en segundos\n",
    "            current_frame_index = int(current_time * video_frame_rate)  # Índice del fotograma correspondiente\n",
    "\n",
    "            # Si el índice del fotograma ha cambiado, leemos y mostramos el nuevo fotograma\n",
    "            if current_frame_index != last_frame_index:\n",
    "                # Rewind a la posición correcta en el video\n",
    "                cap_video.set(cv2.CAP_PROP_POS_FRAMES, current_frame_index)\n",
    "\n",
    "                # Lee el fotograma del video\n",
    "                ret_video, frame_video = cap_video.read()\n",
    "                if not ret_video:\n",
    "                    break  # Si no hay más frames, salimos del bucle\n",
    "\n",
    "                # Convertir la imagen de BGR (OpenCV) a RGB (Pygame)\n",
    "                frame_rgb = cv2.cvtColor(frame_video, cv2.COLOR_BGR2RGB)\n",
    "                current_image = pygame.image.frombuffer(frame_rgb.tobytes(), frame_rgb.shape[1::-1], \"RGB\")\n",
    "\n",
    "                last_frame_index = current_frame_index\n",
    "\n",
    "\n",
    "            # Mostrar el fotograma del video a la izquierda\n",
    "            screen.blit(current_image, (0, 0))\n",
    "\n",
    "            # Leer un fotograma de la cámara\n",
    "            ret_camera, frame_camera = cap_camera.read()\n",
    "            if not ret_camera:\n",
    "                print(\"No se pudo leer el cuadro de la cámara.\")\n",
    "                break\n",
    "\n",
    "            # Procesa la imagen para detectar poses\n",
    "            # results = pose.process(rgb_frame_camera)\n",
    "\n",
    "            # # Dibuja las anotaciones de pose en la imagen original de la cámara\n",
    "            # if results.pose_landmarks:\n",
    "            #     mp_drawing.draw_landmarks(\n",
    "            #         frame_camera, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "            #         mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "            #         mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2)\n",
    "            #     )\n",
    "            \n",
    "\n",
    "                # # Dibujar puntos y conexiones en el video de referencia\n",
    "                # altura, ancho, _ = frame_camera.shape\n",
    "                # for conexion in mp_pose.POSE_CONNECTIONS:\n",
    "                #     inicio = puntos_referencia[conexion[0]]\n",
    "                #     fin = puntos_referencia[conexion[1]]\n",
    "                #     inicio_px = (int(inicio[\"x\"] * ancho), int(inicio[\"y\"] * altura))\n",
    "                #     fin_px = (int(fin[\"x\"] * ancho), int(fin[\"y\"] * altura))\n",
    "                #     cv2.line(frame_camera, inicio_px, fin_px, (255, 0, 0), 2)\n",
    "\n",
    "                # for punto in puntos_referencia:\n",
    "                #     px = (int(punto[\"x\"] * ancho), int(punto[\"y\"] * altura))\n",
    "                #     cv2.circle(frame_camera, px, 5, (0, 255, 0), -1)\n",
    "\n",
    "            frame_camera = cv2.flip(frame_camera, 1)\n",
    "            rgb_frame_cam = cv2.cvtColor(frame_camera, cv2.COLOR_BGR2RGB)\n",
    "            results_cam = pose.process(rgb_frame_cam)\n",
    "\n",
    "\n",
    "            if results_cam.pose_landmarks:\n",
    "                if current_frame_index % 15 == 0:\n",
    "                    score += puntuacion(puntos_video_referencia,current_frame_index,results_cam, frame_camera)\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    frame_camera, results_cam.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                    mp_drawing.DrawingSpec(color=(0, 255, 255), thickness=2, circle_radius=2),\n",
    "                    mp_drawing.DrawingSpec(color=(255, 0, 255), thickness=2, circle_radius=2)\n",
    "                )\n",
    "\n",
    "            cv2.putText(frame_camera, f'Puntuacion: {score}', (10, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        \n",
    "            # Convertir la imagen de la cámara a RGB para Pygame\n",
    "            frame_camera_rgb = cv2.cvtColor(frame_camera, cv2.COLOR_BGR2RGB)\n",
    "            frame_camera_surface = pygame.image.frombuffer(frame_camera_rgb.tobytes(), frame_camera_rgb.shape[1::-1], \"RGB\")\n",
    "\n",
    "            # Mostrar la imagen de la cámara a la derecha\n",
    "            screen.blit(frame_camera_surface, (frame_width, 0))\n",
    "\n",
    "            pygame.display.flip()\n",
    "\n",
    "            # Comprobar eventos, como cerrar la ventana\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == pygame.QUIT:\n",
    "                    cap_video.release()\n",
    "                    cap_camera.release()\n",
    "                    pygame.quit()\n",
    "                    exit()\n",
    "\n",
    "    # Cerrar todo después de la reproducción\n",
    "    cap_video.release()\n",
    "    cap_camera.release()\n",
    "    pygame.quit()\n",
    "\n",
    "# Función para extraer puntos de referencia y guardarlos en un archivo JSON\n",
    "def extraer_y_guardar_puntos(video_path, output_file):\n",
    "    puntos_video_referencia = []\n",
    "\n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        video_cap = cv2.VideoCapture(video_path)\n",
    "        while True:\n",
    "            ret_vid, frame_vid = video_cap.read()\n",
    "            if not ret_vid:\n",
    "                break\n",
    "\n",
    "            # Obtén el índice del frame actual\n",
    "            frame_index = int(video_cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "\n",
    "            rgb_frame_vid = cv2.cvtColor(frame_vid, cv2.COLOR_BGR2RGB)\n",
    "            results_vid = pose.process(rgb_frame_vid)\n",
    "\n",
    "            if results_vid.pose_landmarks:\n",
    "                puntos = []\n",
    "                for landmark in results_vid.pose_landmarks.landmark:\n",
    "                    puntos.append({\n",
    "                        \"x\": landmark.x,\n",
    "                        \"y\": landmark.y,\n",
    "                        \"z\": landmark.z,\n",
    "                        \"visibility\": landmark.visibility\n",
    "                    })\n",
    "\n",
    "                # Agrega los puntos junto con el índice del frame al resultado\n",
    "                puntos_video_referencia.append({\n",
    "                    \"frame\": frame_index,\n",
    "                    \"puntos\": puntos\n",
    "                })\n",
    "\n",
    "        video_cap.release()\n",
    "\n",
    "    # Guarda los puntos en un archivo JSON\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(puntos_video_referencia, f)\n",
    "\n",
    "    print(f\"Puntos de referencia guardados en {output_file}\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    modo = input(\"Seleccione modo: 'extraer' para guardar puntos o 'jugar' para comparar: \")\n",
    "\n",
    "    if modo == 'extraer':\n",
    "        extraer_y_guardar_puntos(dance_video, 'puntos_referencia.json')\n",
    "    elif modo == 'jugar':\n",
    "        jugar_con_puntos('puntos_referencia.json', dance_video)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.11.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "5.533068038962008\n",
      "6.367608347834825\n",
      "20.885193980870753\n",
      "9.296929396072782\n",
      "8.62524713220261\n",
      "42.86169065263305\n",
      "27.906333946983725\n",
      "7.153969500210845\n",
      "8.067364188878496\n",
      "110.21935719605897\n",
      "38.23720911571398\n",
      "6.582141244279704\n",
      "21.699594987259616\n",
      "62.82805396826064\n",
      "40.88977732830045\n",
      "7.032170502806466\n",
      "22.218139951000264\n",
      "61.53372397735613\n",
      "8.980719586486218\n",
      "13.260115104847726\n",
      "3.739607167184584\n",
      "3.2214150432950888\n",
      "4.439356544133818\n",
      "3.90633826991252\n",
      "3.7558273596341647\n",
      "2.716533441268541\n",
      "4.2955027706112405\n",
      "2.8849451586778154\n",
      "3.711706134186792\n",
      "4.183505686051071\n",
      "4.341374347522366\n",
      "4.595540911738387\n",
      "3.014187731498405\n",
      "3.5499272283046746\n",
      "4.226436845072589\n",
      "4.726238466106987\n",
      "3.5733135792707684\n",
      "4.055590563949639\n",
      "4.269661064440211\n",
      "5.110676673712902\n",
      "4.287987373889075\n",
      "4.558664540184836\n",
      "4.564303509362666\n",
      "3.4821667612760465\n",
      "3.308771549441922\n",
      "4.087936055242248\n",
      "4.320761742241466\n",
      "3.614102204177619\n",
      "3.832850045783267\n",
      "4.400648343976506\n",
      "3.2399062143109005\n",
      "7.846663993625555\n",
      "6.418825760387824\n",
      "4.86194077817984\n",
      "4.786459763308615\n",
      "6.77865657228568\n",
      "5.617052444765052\n",
      "4.777392969278154\n",
      "5.246084892647756\n",
      "4.9068350365764974\n",
      "6.169958210581875\n",
      "4.096083137174622\n",
      "4.552292420754685\n",
      "4.664683994296757\n",
      "4.254179882367197\n",
      "3.9843963687006285\n",
      "6.061871341507148\n",
      "3.753716789634062\n",
      "6.606713458967718\n",
      "3.47061157535479\n",
      "7.130640620347762\n",
      "3.5259451378773385\n",
      "4.598726441138326\n",
      "4.081071272363786\n",
      "5.066747652822516\n",
      "5.162970665394279\n",
      "3.294318337350467\n",
      "5.174124200388012\n",
      "3.821968951807167\n",
      "5.906171056752892\n",
      "3.783370199734316\n",
      "5.296082266679163\n",
      "5.119519392802947\n",
      "3.7488612184765198\n",
      "5.614403404003973\n",
      "3.4015614776589294\n",
      "3.928510033910937\n",
      "4.812263645303186\n",
      "4.992368381486412\n",
      "4.899156546581453\n",
      "4.946920485633719\n",
      "3.6366447448785486\n",
      "4.211010326475349\n",
      "4.216669446937861\n",
      "3.314523531188946\n",
      "4.413561745506486\n",
      "3.8841542614820157\n",
      "3.6132497292538064\n",
      "5.086024276765276\n",
      "3.3466022449470696\n",
      "2.8551775866338476\n",
      "4.0091127433543425\n",
      "4.785691960359262\n",
      "4.217336556424356\n",
      "6.953020682215687\n",
      "3.5227303095542593\n",
      "7.971073633483471\n",
      "5.2885637303163975\n",
      "6.8086816272248525\n",
      "4.054093728037309\n",
      "6.023533897815608\n",
      "3.85613876871794\n",
      "4.702743367543363\n",
      "3.940491987198206\n",
      "3.238179675042012\n",
      "5.496430783647906\n",
      "3.4784516480483454\n",
      "33.623530287682115\n",
      "4.950970598421275\n",
      "5.273643863247972\n",
      "4.625447432765173\n",
      "6.158588617994418\n",
      "3.638311901930983\n",
      "1.7770229830561557\n",
      "2.9752503982929044\n",
      "5.667488020407332\n",
      "3.2332814846320357\n",
      "3.2709207487126997\n",
      "3.2403059088544923\n",
      "6.291782807476404\n",
      "2.003057900503134\n",
      "2.7859148965566547\n",
      "4.932112347085229\n",
      "3.2503240569169694\n",
      "2.480453512111578\n",
      "3.017125448752955\n",
      "2.485824671034694\n",
      "3.512710330200128\n",
      "2.3001884507656016\n",
      "1.7806027814870926\n",
      "3.6519239699383537\n",
      "3.541037112744061\n",
      "3.8681115902037604\n",
      "3.1593618568830246\n",
      "4.628860583785652\n",
      "3.3667833558662332\n",
      "2.264643263036112\n",
      "3.9819721950684963\n",
      "2.3854286222647576\n",
      "3.9966595530444256\n",
      "4.047742495240558\n",
      "11.80429685866537\n",
      "4.757500511045157\n",
      "3.9708745945185764\n",
      "4.085874339300017\n",
      "4.369944853923911\n",
      "5.579572225957632\n",
      "5.339632477910246\n",
      "5.0437167850459765\n",
      "5.6870187751396495\n",
      "5.24895508702796\n",
      "5.049639975944402\n",
      "5.369284593251394\n",
      "6.0449640945441\n",
      "5.825959734818844\n",
      "5.685995498244292\n",
      "5.047131650398599\n",
      "5.313787997529255\n",
      "4.930838022887046\n",
      "5.580238783788159\n",
      "5.715536609503526\n",
      "4.695953015406582\n",
      "5.353500413051693\n",
      "5.160685415567285\n",
      "5.625224740128746\n",
      "5.120538262116358\n",
      "6.346653810804595\n",
      "5.80044972772429\n",
      "5.663861686438184\n",
      "5.718479702361445\n",
      "5.557934426576699\n",
      "5.322234405576465\n",
      "5.389812077543762\n",
      "4.872344060131667\n",
      "5.661211266872678\n",
      "5.394627783284892\n",
      "7.796697587707999\n",
      "6.376386644569975\n",
      "6.3606726194138385\n",
      "6.339048816057118\n",
      "6.112691905605526\n",
      "5.5264194245029605\n",
      "5.576035371072829\n",
      "6.141074172991192\n",
      "8.737712619840323\n",
      "6.130638923560952\n",
      "5.373437977099286\n",
      "4.791173267684934\n",
      "5.696748245399034\n",
      "5.538210549498074\n",
      "6.171663976994758\n",
      "5.588656287745474\n",
      "7.1316358820606816\n",
      "4.37611952948265\n",
      "5.587271715292724\n",
      "5.165304169323201\n",
      "5.341759816611429\n",
      "6.088720930222126\n",
      "5.74894530418583\n",
      "6.398197815686757\n",
      "5.733714467322646\n",
      "6.213638124219713\n",
      "4.696898290151357\n",
      "5.761835385292428\n",
      "4.798541483283081\n",
      "6.60416741786336\n",
      "6.649818794704401\n",
      "8.523198905471714\n",
      "6.084040385661689\n",
      "8.099695790803068\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pygame\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import json\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "\n",
    "# Inicializa los módulos de Mediapipe\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "\n",
    "# Configuración del video de referencia\n",
    "dance_video = 'dance_video.mp4'\n",
    "\n",
    "# Configuración\n",
    "process_every_n_frames = 15\n",
    "\n",
    "def calcular_distancia_escala(puntos):\n",
    "    hombro_izquierdo = puntos[11]\n",
    "    hombro_derecho = puntos[12]\n",
    "    return np.linalg.norm(np.array([hombro_izquierdo[\"x\"], hombro_izquierdo[\"y\"]]) -\n",
    "                          np.array([hombro_derecho[\"x\"], hombro_derecho[\"y\"]]))\n",
    "\n",
    "def calcular_similitud(puntos1, puntos2, escala1, escala2):\n",
    "    if not puntos1 or not puntos2 or len(puntos1) != len(puntos2):\n",
    "        return 0\n",
    "\n",
    "    distancias = []\n",
    "    for p1, p2 in zip(puntos1, puntos2):\n",
    "        p1_escalado = np.array([p1[\"x\"] / escala1, p1[\"y\"] / escala1, p1[\"z\"] / escala1])\n",
    "        p2_escalado = np.array([p2[\"x\"] / escala2, p2[\"y\"] / escala2, p2[\"z\"] / escala2])\n",
    "        distancias.append(np.linalg.norm(p1_escalado - p2_escalado))\n",
    "\n",
    "    return np.mean(distancias)\n",
    "\n",
    "def obtener_puntos_por_frame(json_data, frame_buscado):\n",
    "    for entrada in json_data:\n",
    "        if entrada[\"frame\"] == frame_buscado:\n",
    "            return entrada[\"puntos\"]\n",
    "    return None\n",
    "\n",
    "def puntuacion(json_file, frame_buscado, results_cam):\n",
    "    puntos_referencia = obtener_puntos_por_frame(json_file, frame_buscado)\n",
    "    if puntos_referencia:\n",
    "        puntos_usuario = [\n",
    "            {\"x\": lm.x, \"y\": lm.y, \"z\": lm.z, \"visibility\": lm.visibility}\n",
    "            for lm in results_cam.pose_landmarks.landmark\n",
    "        ]\n",
    "\n",
    "        escala_referencia = calcular_distancia_escala(puntos_referencia)\n",
    "        escala_usuario = calcular_distancia_escala(puntos_usuario)\n",
    "\n",
    "        similitud = calcular_similitud(puntos_referencia, puntos_usuario, escala_referencia, escala_usuario)\n",
    "\n",
    "        print(similitud)\n",
    "\n",
    "        if similitud < 2:\n",
    "            return 100\n",
    "        elif similitud < 5:\n",
    "            return 50\n",
    "        else:\n",
    "            return 0\n",
    "    return 0\n",
    "\n",
    "def process_video(cap_video, video_queue, video_frame_rate):\n",
    "    while cap_video.isOpened():\n",
    "        current_time = pygame.mixer.music.get_pos() / 1_000\n",
    "        current_frame_index = int(current_time * video_frame_rate)\n",
    "\n",
    "        cap_video.set(cv2.CAP_PROP_POS_FRAMES, current_frame_index)\n",
    "        ret_video, frame_video = cap_video.read()\n",
    "        if not ret_video:\n",
    "            break\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(frame_video, cv2.COLOR_BGR2RGB)\n",
    "        video_queue.put(frame_rgb)\n",
    "\n",
    "    cap_video.release()\n",
    "\n",
    "def process_camera(cap_camera, camera_queue, json_file, video_frame_rate):\n",
    "    frame_count = 0\n",
    "    score = 0\n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        while cap_camera.isOpened():\n",
    "            ret_camera, frame_camera = cap_camera.read()\n",
    "            if not ret_camera:\n",
    "                break\n",
    "\n",
    "            frame_camera = cv2.flip(frame_camera, 1)\n",
    "            rgb_frame_cam = cv2.cvtColor(frame_camera, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            frame_count += 1\n",
    "            if frame_count % process_every_n_frames == 0:\n",
    "                results_cam = pose.process(rgb_frame_cam)\n",
    "                if results_cam.pose_landmarks:\n",
    "                    current_time = pygame.mixer.music.get_pos() / 1_000\n",
    "                    current_frame_index = int(current_time * video_frame_rate)\n",
    "                    score += puntuacion(json_file, current_frame_index, results_cam)\n",
    "\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        frame_camera, results_cam.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                        mp_drawing.DrawingSpec(color=(0, 255, 255), thickness=2, circle_radius=2),\n",
    "                        mp_drawing.DrawingSpec(color=(255, 0, 255), thickness=2, circle_radius=2)\n",
    "                    )\n",
    "\n",
    "            cv2.putText(frame_camera, f'Puntuacion: {score}', (10, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            camera_queue.put(frame_camera)\n",
    "\n",
    "    cap_camera.release()\n",
    "\n",
    "def jugar_con_puntos(json_file, video_path):\n",
    "    with open(json_file, 'r') as f:\n",
    "        puntos_video_referencia = json.load(f)\n",
    "\n",
    "    pygame.init()\n",
    "    audio_file = 'audio_extraido.mp3'\n",
    "    pygame.mixer.music.load(audio_file)\n",
    "    pygame.mixer.music.play()\n",
    "\n",
    "    cap_video = cv2.VideoCapture(video_path)\n",
    "    cap_camera = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap_video.isOpened() or not cap_camera.isOpened():\n",
    "        print(\"Error: No se pudo abrir el video o la cámara.\")\n",
    "        return\n",
    "\n",
    "    frame_width = int(cap_video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    video_frame_rate = cap_video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    screen_width = frame_width * 2\n",
    "    screen_height = frame_height\n",
    "    screen = pygame.display.set_mode((screen_width, screen_height))\n",
    "\n",
    "    video_queue = Queue()\n",
    "    camera_queue = Queue()\n",
    "\n",
    "    video_thread = Thread(target=process_video, args=(cap_video, video_queue, video_frame_rate))\n",
    "    camera_thread = Thread(target=process_camera, args=(cap_camera, camera_queue, puntos_video_referencia, video_frame_rate))\n",
    "\n",
    "    video_thread.start()\n",
    "    camera_thread.start()\n",
    "\n",
    "    while video_thread.is_alive() or camera_thread.is_alive():\n",
    "        if not video_queue.empty():\n",
    "            frame_rgb = video_queue.get()\n",
    "            current_image = pygame.image.frombuffer(frame_rgb.tobytes(), frame_rgb.shape[1::-1], \"RGB\")\n",
    "            screen.blit(current_image, (0, 0))\n",
    "\n",
    "        if not camera_queue.empty():\n",
    "            frame_camera = camera_queue.get()\n",
    "            frame_camera_rgb = cv2.cvtColor(frame_camera, cv2.COLOR_BGR2RGB)\n",
    "            frame_camera_surface = pygame.image.frombuffer(frame_camera_rgb.tobytes(), frame_camera_rgb.shape[1::-1], \"RGB\")\n",
    "            screen.blit(frame_camera_surface, (frame_width, 0))\n",
    "\n",
    "        pygame.display.flip()\n",
    "\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                video_thread.join()\n",
    "                camera_thread.join()\n",
    "                cap_video.release()\n",
    "                cap_camera.release()\n",
    "                pygame.quit()\n",
    "                return\n",
    "\n",
    "    video_thread.join()\n",
    "    camera_thread.join()\n",
    "    cap_video.release()\n",
    "    cap_camera.release()\n",
    "    pygame.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    modo = input(\"Seleccione modo: 'extraer' para guardar puntos o 'jugar' para comparar: \")\n",
    "\n",
    "    if modo == 'extraer':\n",
    "        extraer_y_guardar_puntos(dance_video, 'puntos_referencia.json')\n",
    "    elif modo == 'jugar':\n",
    "        jugar_con_puntos('puntos_referencia.json', dance_video)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.113399383303076\n",
      "10.757642716612661\n",
      "49.41278613508071\n",
      "9.146528536879464\n",
      "11.486701177843711\n",
      "23.017846363749566\n",
      "6.175157117679301\n",
      "45.48207176056337\n",
      "8.894321888841421\n",
      "8.725809166826988\n",
      "3.9957589999824865\n",
      "4.411978531524868\n",
      "5.206003225302198\n",
      "3.920628186651439\n",
      "4.25183353517686\n",
      "4.332453992293823\n",
      "4.910661762570328\n",
      "3.1651554728044777\n",
      "4.618697002084217\n",
      "3.85496276713027\n",
      "4.006228644722784\n",
      "4.571261829984873\n",
      "9.436003863333298\n",
      "6.457013534036639\n",
      "7.646472940305514\n",
      "5.574945951445029\n",
      "7.611838280347926\n",
      "5.446369463699101\n",
      "5.481292776150678\n",
      "5.189663259393166\n",
      "7.377489453081635\n",
      "6.961062593325984\n",
      "5.457822188170198\n",
      "4.793495058696249\n",
      "3.999291336414404\n",
      "6.045808333526707\n",
      "5.167473875159979\n",
      "4.479851846436889\n",
      "5.017840552457486\n",
      "6.806062013260599\n",
      "6.823157200362158\n",
      "5.827494026162199\n",
      "5.89671878826592\n",
      "4.6650101515070785\n",
      "5.474006398933915\n",
      "5.810630648322229\n",
      "5.567091015382705\n",
      "5.632912478407797\n",
      "6.484640351412736\n",
      "8.22203691053085\n",
      "5.702990248168372\n",
      "5.760297522363961\n",
      "6.919116315709512\n",
      "6.2598967259188365\n",
      "6.480956060929415\n",
      "5.720222437195599\n",
      "6.212656614697872\n",
      "4.852052595791866\n",
      "5.44080918496729\n",
      "4.678954772259254\n",
      "5.210932739890341\n",
      "5.596931744904455\n",
      "3.8873263446581823\n",
      "5.196468252297264\n",
      "3.6284509741021647\n",
      "4.825324614533667\n",
      "4.69905128215696\n",
      "5.454363574999817\n",
      "4.7755104270259245\n",
      "4.954100798780429\n",
      "3.6885664112822814\n",
      "2.4518242266574037\n",
      "4.189349421222239\n",
      "4.0321520837768965\n",
      "5.183973218404147\n",
      "4.150091313142123\n",
      "5.611694080900247\n",
      "4.446118312177399\n",
      "3.9770952227530834\n",
      "3.1808943335489386\n",
      "3.6342900894618797\n",
      "3.705371968226781\n",
      "3.08382299287264\n",
      "2.4470408159572727\n",
      "3.5697326357013646\n",
      "3.8613416377768424\n",
      "5.918748258204243\n",
      "6.9077392252313325\n",
      "5.238702696879959\n",
      "6.864632195090546\n",
      "7.098838982215886\n",
      "5.692013755619044\n",
      "6.91975769416364\n",
      "5.204497441062504\n",
      "7.975975144905545\n",
      "6.202707502111635\n",
      "6.453016323153675\n",
      "6.98931532961353\n",
      "6.373720450861449\n",
      "5.473882614746014\n",
      "7.500784777119402\n",
      "6.812346089262757\n",
      "6.971844994313167\n",
      "8.472408254289451\n",
      "11.596819805818518\n",
      "11.045996559022155\n",
      "9.072440857982198\n",
      "7.405150567733668\n",
      "7.3326681327299115\n",
      "7.064838090195139\n",
      "6.719212487682618\n",
      "11.039850929134095\n",
      "7.631529734025655\n",
      "7.208879908115804\n",
      "5.7328526995535976\n",
      "7.908784025202861\n",
      "5.5156896910800715\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pygame\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image, ImageSequence\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "\n",
    "# Inicializa los módulos de Mediapipe\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "\n",
    "# Configuración del video de referencia\n",
    "dance_video = 'dance_video.mp4'\n",
    "\n",
    "# Configuración\n",
    "process_every_n_frames = 30\n",
    "\n",
    "stop_threads = False  # Bandera para detener los hilos\n",
    "\n",
    "# Crear un índice para cambiar entre los frames del GIF\n",
    "gif_index = 0\n",
    "# Convertir el GIF en una lista de frames de imágenes\n",
    "gif_frames = []\n",
    "\n",
    "def overlay_image(frame, overlay, x, y):\n",
    "    \"\"\"\n",
    "    Superpone una imagen sobre un frame en las coordenadas (x, y).\n",
    "    \"\"\"\n",
    "    overlay_height, overlay_width = overlay.shape[:2]\n",
    "    alpha_overlay = None\n",
    "\n",
    "    # Si la imagen tiene canal alfa, úsalo\n",
    "    if overlay.shape[2] == 4:\n",
    "        alpha_overlay = overlay[:, :, 3] / 255.0  # Normaliza el canal alfa\n",
    "        overlay = overlay[:, :, :3]  # Elimina el canal alfa para la mezcla\n",
    "\n",
    "    # Seleccionar la región de interés (ROI) en el frame\n",
    "    roi = frame[y:y+overlay_height, x:x+overlay_width]\n",
    "\n",
    "    # Combinación usando el canal alfa (si existe)\n",
    "    if alpha_overlay is not None:\n",
    "        for c in range(3):  # Mezcla cada canal (B, G, R)\n",
    "            roi[:, :, c] = (alpha_overlay * overlay[:, :, c] +\n",
    "                            (1 - alpha_overlay) * roi[:, :, c])\n",
    "    else:\n",
    "        # Sin canal alfa, simplemente reemplaza los píxeles\n",
    "        frame[y:y+overlay_height, x:x+overlay_width] = overlay\n",
    "\n",
    "# Función para actualizar el índice del GIF y obtener el siguiente frame\n",
    "def get_next_gif_frame():\n",
    "    global gif_index\n",
    "    if gif_index < len(gif_frames):  # Aumenta el índice solo si hay fotogramas disponibles\n",
    "        frame = cv2.resize(gif_frames[gif_index], (100, 100))\n",
    "        gif_index += 1\n",
    "        return frame\n",
    "    return None  # Devuelve None después de completar el GIF\n",
    "\n",
    "\n",
    "def change_gif(score):\n",
    "    global gif_index\n",
    "    global gif\n",
    "    global gif_frames\n",
    "    \n",
    "    gif_index=0\n",
    "    # Cargar el archivo GIF usando PIL\n",
    "    if score==100:\n",
    "        gif_path = \"./assets/perfect.gif\"\n",
    "    elif score==50:\n",
    "        gif_path = \"./assets/good.gif\"\n",
    "    else:\n",
    "        gif_path = \"./assets/fail.gif\"  # Ruta al archivo GIF\n",
    "\n",
    "    gif = Image.open(gif_path)\n",
    "    # Convertir el GIF en una lista de frames de imágenes\n",
    "    gif_frames = []\n",
    "    for frame in ImageSequence.Iterator(gif):\n",
    "        frame = frame.convert(\"RGBA\")  # Asegurarse de que el GIF tenga un canal alfa\n",
    "        gif_frames.append(np.array(frame))\n",
    "        \n",
    "\n",
    "def calcular_distancia_escala(puntos):\n",
    "    hombro_izquierdo = puntos[11]\n",
    "    hombro_derecho = puntos[12]\n",
    "    return np.linalg.norm(np.array([hombro_izquierdo[\"x\"], hombro_izquierdo[\"y\"]]) -\n",
    "                          np.array([hombro_derecho[\"x\"], hombro_derecho[\"y\"]]))\n",
    "\n",
    "def calcular_similitud(puntos1, puntos2, escala1, escala2):\n",
    "    if not puntos1 or not puntos2 or len(puntos1) != len(puntos2):\n",
    "        return 0\n",
    "\n",
    "    distancias = []\n",
    "    for p1, p2 in zip(puntos1, puntos2):\n",
    "        p1_escalado = np.array([p1[\"x\"] / escala1, p1[\"y\"] / escala1, p1[\"z\"] / escala1])\n",
    "        p2_escalado = np.array([p2[\"x\"] / escala2, p2[\"y\"] / escala2, p2[\"z\"] / escala2])\n",
    "        distancias.append(np.linalg.norm(p1_escalado - p2_escalado))\n",
    "\n",
    "    return np.mean(distancias)\n",
    "\n",
    "def obtener_puntos_por_frame(json_data, frame_buscado):\n",
    "    for entrada in json_data:\n",
    "        if entrada[\"frame\"] == frame_buscado:\n",
    "            return entrada[\"puntos\"]\n",
    "    return None\n",
    "\n",
    "def puntuacion(json_file, frame_buscado, results_cam):\n",
    "    puntos_referencia = obtener_puntos_por_frame(json_file, frame_buscado)\n",
    "    if puntos_referencia:\n",
    "        puntos_usuario = [\n",
    "            {\"x\": lm.x, \"y\": lm.y, \"z\": lm.z, \"visibility\": lm.visibility}\n",
    "            for lm in results_cam.pose_landmarks.landmark\n",
    "        ]\n",
    "\n",
    "        escala_referencia = calcular_distancia_escala(puntos_referencia)\n",
    "        escala_usuario = calcular_distancia_escala(puntos_usuario)\n",
    "\n",
    "        similitud = calcular_similitud(puntos_referencia, puntos_usuario, escala_referencia, escala_usuario)\n",
    "\n",
    "        print(similitud)\n",
    "\n",
    "        if similitud < 3:\n",
    "            change_gif(100)\n",
    "            return 100\n",
    "        elif similitud < 5:\n",
    "            change_gif(50)\n",
    "            return 50\n",
    "        else:\n",
    "            change_gif(0)\n",
    "            return 0\n",
    "    return 0\n",
    "\n",
    "def process_video(cap_video, video_queue, video_frame_rate, frame_width, frame_height):\n",
    "    global stop_threads\n",
    "    while cap_video.isOpened() and not stop_threads:\n",
    "        current_time = pygame.mixer.music.get_pos() / 1_000\n",
    "        current_frame_index = int(current_time * video_frame_rate)\n",
    "\n",
    "        cap_video.set(cv2.CAP_PROP_POS_FRAMES, current_frame_index)\n",
    "        ret_video, frame_video = cap_video.read()\n",
    "        if not ret_video:\n",
    "            break\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(frame_video, cv2.COLOR_BGR2RGB)\n",
    "        frame_rgb = cv2.resize(frame_rgb, (frame_width, frame_height))  # Reducir tamaño\n",
    "\n",
    "        gif_frame = get_next_gif_frame()\n",
    "        if gif_frame is not None:\n",
    "            overlay_image(frame_rgb, gif_frame, 0, 0)\n",
    "\n",
    "        video_queue.put(frame_rgb)\n",
    "\n",
    "    cap_video.release()\n",
    "\n",
    "def process_camera(cap_camera, camera_queue, json_file, video_frame_rate, frame_width, frame_height):\n",
    "    global stop_threads\n",
    "    frame_count = 0\n",
    "    score = 0\n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        while cap_camera.isOpened() and not stop_threads:\n",
    "            ret_camera, frame_camera = cap_camera.read()\n",
    "            if not ret_camera:\n",
    "                break\n",
    "\n",
    "            frame_camera = cv2.flip(frame_camera, 1)\n",
    "            frame_camera = cv2.resize(frame_camera, (frame_width, frame_height))\n",
    "            rgb_frame_cam = cv2.cvtColor(frame_camera, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            frame_count += 1\n",
    "            if frame_count % process_every_n_frames == 0:\n",
    "                results_cam = pose.process(rgb_frame_cam)\n",
    "                if results_cam.pose_landmarks:\n",
    "                    current_time = pygame.mixer.music.get_pos() / 1_000\n",
    "                    current_frame_index = int(current_time * video_frame_rate)\n",
    "                    score += puntuacion(json_file, current_frame_index, results_cam)\n",
    "\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        frame_camera, results_cam.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                        mp_drawing.DrawingSpec(color=(0, 255, 255), thickness=2, circle_radius=2),\n",
    "                        mp_drawing.DrawingSpec(color=(255, 0, 255), thickness=2, circle_radius=2)\n",
    "                    )\n",
    "\n",
    "            cv2.putText(frame_camera, f'Puntuacion: {score}', (10, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            camera_queue.put(frame_camera)\n",
    "\n",
    "    cap_camera.release()\n",
    "\n",
    "def jugar_con_puntos(json_file, video_path):\n",
    "    global stop_threads\n",
    "\n",
    "    with open(json_file, 'r') as f:\n",
    "        puntos_video_referencia = json.load(f)\n",
    "\n",
    "    pygame.init()\n",
    "    audio_file = 'audio_extraido.mp3'\n",
    "    pygame.mixer.music.load(audio_file)\n",
    "    pygame.mixer.music.play()\n",
    "\n",
    "    cap_video = cv2.VideoCapture(video_path)\n",
    "    cap_camera = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap_video.isOpened() or not cap_camera.isOpened():\n",
    "        print(\"Error: No se pudo abrir el video o la cámara.\")\n",
    "        return\n",
    "\n",
    "    frame_width = int(cap_video.get(cv2.CAP_PROP_FRAME_WIDTH)) // 2  # Reducir a la mitad\n",
    "    frame_height = int(cap_video.get(cv2.CAP_PROP_FRAME_HEIGHT)) // 2  # Reducir a la mitad\n",
    "    video_frame_rate = cap_video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    screen_width = frame_width * 2  # Doblar para mostrar video + cámara\n",
    "    screen_height = frame_height\n",
    "    screen = pygame.display.set_mode((screen_width, screen_height))  # Usar dimensiones reducidas\n",
    "\n",
    "    video_queue = Queue()\n",
    "    camera_queue = Queue()\n",
    "\n",
    "    video_thread = Thread(target=process_video, args=(cap_video, video_queue, video_frame_rate, frame_width, frame_height))\n",
    "    camera_thread = Thread(target=process_camera, args=(cap_camera, camera_queue, puntos_video_referencia, video_frame_rate, frame_width, frame_height))\n",
    "\n",
    "    video_thread.start()\n",
    "    camera_thread.start()\n",
    "\n",
    "    while video_thread.is_alive() or camera_thread.is_alive():\n",
    "        if not video_queue.empty():\n",
    "            frame_rgb = video_queue.get()\n",
    "            current_image = pygame.image.frombuffer(frame_rgb.tobytes(), frame_rgb.shape[1::-1], \"RGB\")\n",
    "            screen.blit(current_image, (0, 0))\n",
    "\n",
    "        if not camera_queue.empty():\n",
    "            frame_camera = camera_queue.get()\n",
    "            frame_camera_rgb = cv2.cvtColor(frame_camera, cv2.COLOR_BGR2RGB)\n",
    "            frame_camera_surface = pygame.image.frombuffer(frame_camera_rgb.tobytes(), frame_camera_rgb.shape[1::-1], \"RGB\")\n",
    "            screen.blit(frame_camera_surface, (frame_width, 0))\n",
    "\n",
    "        pygame.display.flip()\n",
    "\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                stop_threads = True\n",
    "                video_thread.join()\n",
    "                camera_thread.join()\n",
    "                cap_video.release()\n",
    "                cap_camera.release()\n",
    "                pygame.quit()\n",
    "                return\n",
    "\n",
    "    stop_threads = True\n",
    "    video_thread.join()\n",
    "    camera_thread.join()\n",
    "    cap_video.release()\n",
    "    cap_camera.release()\n",
    "    pygame.quit()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    modo = input(\"Seleccione modo: 'extraer' para guardar puntos o 'jugar' para comparar: \")\n",
    "\n",
    "    if modo == 'extraer':\n",
    "        extraer_y_guardar_puntos(dance_video, 'puntos_referencia.json')\n",
    "    elif modo == 'jugar':\n",
    "        jugar_con_puntos('puntos_referencia.json', dance_video)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
